{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml2_group_assignment.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green> Introduction </font>\n",
    "\n",
    "The assignment is focused on solving the Forest Cover Type Prediction: https://www.kaggle.com/c/forest-cover-type-prediction/overview. This task proposes a classification problem: predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data).\n",
    "\n",
    "The study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. The seven types are:\n",
    "\n",
    "1. Spruce/Fir\n",
    "2. Lodgepole Pine\n",
    "3. Ponderosa Pine\n",
    "4. Cottonwood/Willow\n",
    "5. Aspen\n",
    "6. Douglas-fir\n",
    "7. Krummholz\n",
    "\n",
    "The training set (15120 observations) contains both features and the Cover_Type. The test set contains only the features. \n",
    "\n",
    "**You must predict the Cover_Type for every row in the test set (565892 observations).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tree_types.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to work on the assignment\n",
    "\n",
    "I expect 3 files from each group:\n",
    "* **A file containing the best predictions from your best model (20%)**\n",
    "* **A Jupyter notebook containing all the work the team did in order to deliver the best predictions (40%)**\n",
    "* **A business report (40%)** explaining:\n",
    "    * The goal\n",
    "    * The work performed: include some detail about data cleaning, feature engineering and modelling\n",
    "    * The results: meaningful metrics for the best models\n",
    "    * Visualizations\n",
    "\n",
    "No group presentation is expected for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green> Table of contents </font>\n",
    "\n",
    "* Data Analysis\n",
    "* Exploratory Data Analysis\n",
    "* Feature Engineering & Selection\n",
    "* Compare Several Machine Learning Models\n",
    "* Perform Hyperparameter Tuning on the Best Model\n",
    "* Interpret Model Results\n",
    "* Evaluate the Best Model with Test Data (replying the initiating question)\n",
    "* Summary & Conclusions\n",
    "\n",
    "# Sections \n",
    "* [Libaries used](#0)\n",
    "* [1. Import Data](#1)\n",
    "* [2. Data analysis](#2)  \n",
    "  * [2.1.Explanation of variables](#2.1)\n",
    "      * [1.2.1 XX](#2.1.1)\n",
    "* [3. Exploratory Data Analysis](#3)\n",
    "  * [3.1 Analysis of the Dataset using EDA](#3.1)\n",
    "  * [3.2 D'Agostino and Pearson's Test](#3.2)  \n",
    "  * [3.3 Checking Variable Completeness ](#3.3)\n",
    "  * [3.4 Correlation Matrix ](#3.4)  \n",
    "  * [3.5 Paired density, scatterplot matrix and 3D Graphics ](#3.5)   \n",
    "  * [3.6 Categorial EDA ](#3.6) \n",
    "      * [3.6.1 Categorial Bar Diagrams](#3.6.1)  \n",
    "      * [3.6.2.Violinplot with Dependent Variable](#3.6.2)  \n",
    "      * [3.6.3.Treemap for categorial Data](#3.6.3) \n",
    "* [4. Baseline Model](#4)\n",
    "  * [4.0 Prepare Data and Standardization](#4.0)\n",
    "  * [4.1 Random Forest](#4.1) \n",
    "  * [4.2 Gradient Boosting](#4.2)  \n",
    "  * [4.3 Decision Trees](#4.3)\n",
    "  * [4.4 K-Nearest Neighbors (KNN)](#4.4)  \n",
    "  * [4.5 Logistic Regression](#4.5) \n",
    "  * [4.6 Naive Bayes](#4.6) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"roosevelt-national-forest.jpeg\" width=1200 height=800 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# <font color=green> Libaries used </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  # Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify #treemap\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from yellowbrick.classifier import ROCAUC\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "##  <font color=green>1.Import the Data </font>\n",
    "Let’s load the training data and create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the original dataset for later comparisons and make a copy for the FE process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15115</th>\n",
       "      <td>15116</td>\n",
       "      <td>2607</td>\n",
       "      <td>243</td>\n",
       "      <td>23</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>660</td>\n",
       "      <td>170</td>\n",
       "      <td>251</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15116</th>\n",
       "      <td>15117</td>\n",
       "      <td>2603</td>\n",
       "      <td>121</td>\n",
       "      <td>19</td>\n",
       "      <td>633</td>\n",
       "      <td>195</td>\n",
       "      <td>618</td>\n",
       "      <td>249</td>\n",
       "      <td>221</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>15118</td>\n",
       "      <td>2492</td>\n",
       "      <td>134</td>\n",
       "      <td>25</td>\n",
       "      <td>365</td>\n",
       "      <td>117</td>\n",
       "      <td>335</td>\n",
       "      <td>250</td>\n",
       "      <td>220</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15118</th>\n",
       "      <td>15119</td>\n",
       "      <td>2487</td>\n",
       "      <td>167</td>\n",
       "      <td>28</td>\n",
       "      <td>218</td>\n",
       "      <td>101</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>237</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15119</th>\n",
       "      <td>15120</td>\n",
       "      <td>2475</td>\n",
       "      <td>197</td>\n",
       "      <td>34</td>\n",
       "      <td>319</td>\n",
       "      <td>78</td>\n",
       "      <td>270</td>\n",
       "      <td>189</td>\n",
       "      <td>244</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "15115  15116       2607     243     23                               258   \n",
       "15116  15117       2603     121     19                               633   \n",
       "15117  15118       2492     134     25                               365   \n",
       "15118  15119       2487     167     28                               218   \n",
       "15119  15120       2475     197     34                               319   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "15115                               7                              660   \n",
       "15116                             195                              618   \n",
       "15117                             117                              335   \n",
       "15118                             101                              242   \n",
       "15119                              78                              270   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "15115            170             251            214  ...            0   \n",
       "15116            249             221             91  ...            0   \n",
       "15117            250             220             83  ...            0   \n",
       "15118            229             237            119  ...            0   \n",
       "15119            189             244            164  ...            0   \n",
       "\n",
       "       Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "15115            0            0            0            0            0   \n",
       "15116            0            0            0            0            0   \n",
       "15117            0            0            0            0            0   \n",
       "15118            0            0            0            0            0   \n",
       "15119            0            0            0            0            0   \n",
       "\n",
       "       Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "15115            0            0            0           3  \n",
       "15116            0            0            0           3  \n",
       "15117            0            0            0           3  \n",
       "15118            0            0            0           3  \n",
       "15119            0            0            0           3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15121</td>\n",
       "      <td>2680</td>\n",
       "      <td>354</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2684</td>\n",
       "      <td>196</td>\n",
       "      <td>214</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15122</td>\n",
       "      <td>2683</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2654</td>\n",
       "      <td>201</td>\n",
       "      <td>216</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15123</td>\n",
       "      <td>2713</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2980</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15124</td>\n",
       "      <td>2709</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2950</td>\n",
       "      <td>208</td>\n",
       "      <td>201</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15125</td>\n",
       "      <td>2706</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2920</td>\n",
       "      <td>210</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  15121       2680     354     14                                 0   \n",
       "1  15122       2683       0     13                                 0   \n",
       "2  15123       2713      16     15                                 0   \n",
       "3  15124       2709      24     17                                 0   \n",
       "4  15125       2706      29     19                                 0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                             2684   \n",
       "1                               0                             2654   \n",
       "2                               0                             2980   \n",
       "3                               0                             2950   \n",
       "4                               0                             2920   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  \\\n",
       "0            196             214            156  ...            0   \n",
       "1            201             216            152  ...            0   \n",
       "2            206             208            137  ...            0   \n",
       "3            208             201            125  ...            0   \n",
       "4            210             195            115  ...            0   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "      <td>565892.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>298066.500000</td>\n",
       "      <td>2964.977407</td>\n",
       "      <td>155.629558</td>\n",
       "      <td>14.039635</td>\n",
       "      <td>270.556622</td>\n",
       "      <td>46.294408</td>\n",
       "      <td>2367.143116</td>\n",
       "      <td>212.131133</td>\n",
       "      <td>223.435026</td>\n",
       "      <td>142.726951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.023236</td>\n",
       "      <td>0.014651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>163359.093603</td>\n",
       "      <td>273.157030</td>\n",
       "      <td>111.962120</td>\n",
       "      <td>7.450155</td>\n",
       "      <td>212.500153</td>\n",
       "      <td>58.209469</td>\n",
       "      <td>1561.482002</td>\n",
       "      <td>26.661063</td>\n",
       "      <td>19.668053</td>\n",
       "      <td>38.030094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206795</td>\n",
       "      <td>0.288444</td>\n",
       "      <td>0.269277</td>\n",
       "      <td>0.052916</td>\n",
       "      <td>0.056137</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.159827</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.120152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15121.000000</td>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>156593.750000</td>\n",
       "      <td>2818.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1116.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>298066.500000</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>439539.250000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3349.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id      Elevation         Aspect          Slope  \\\n",
       "count  565892.000000  565892.000000  565892.000000  565892.000000   \n",
       "mean   298066.500000    2964.977407     155.629558      14.039635   \n",
       "std    163359.093603     273.157030     111.962120       7.450155   \n",
       "min     15121.000000    1859.000000       0.000000       0.000000   \n",
       "25%    156593.750000    2818.000000      58.000000       9.000000   \n",
       "50%    298066.500000    2999.000000     127.000000      13.000000   \n",
       "75%    439539.250000    3164.000000     260.000000      18.000000   \n",
       "max    581012.000000    3858.000000     360.000000      66.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                     565892.000000                   565892.000000   \n",
       "mean                         270.556622                       46.294408   \n",
       "std                          212.500153                       58.209469   \n",
       "min                            0.000000                     -173.000000   \n",
       "25%                          108.000000                        7.000000   \n",
       "50%                          228.000000                       29.000000   \n",
       "75%                          390.000000                       69.000000   \n",
       "max                         1397.000000                      601.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                    565892.000000  565892.000000   565892.000000   \n",
       "mean                       2367.143116     212.131133      223.435026   \n",
       "std                        1561.482002      26.661063       19.668053   \n",
       "min                           0.000000       0.000000        0.000000   \n",
       "25%                        1116.000000     198.000000      213.000000   \n",
       "50%                        2018.000000     218.000000      226.000000   \n",
       "75%                        3349.000000     231.000000      237.000000   \n",
       "max                        7117.000000     254.000000      254.000000   \n",
       "\n",
       "       Hillshade_3pm  ...    Soil_Type31    Soil_Type32    Soil_Type33  \\\n",
       "count  565892.000000  ...  565892.000000  565892.000000  565892.000000   \n",
       "mean      142.726951  ...       0.044768       0.091588       0.078704   \n",
       "std        38.030094  ...       0.206795       0.288444       0.269277   \n",
       "min         0.000000  ...       0.000000       0.000000       0.000000   \n",
       "25%       119.000000  ...       0.000000       0.000000       0.000000   \n",
       "50%       143.000000  ...       0.000000       0.000000       0.000000   \n",
       "75%       168.000000  ...       0.000000       0.000000       0.000000   \n",
       "max       254.000000  ...       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type34    Soil_Type35    Soil_Type36    Soil_Type37  \\\n",
       "count  565892.000000  565892.000000  565892.000000  565892.000000   \n",
       "mean        0.002808       0.003161       0.000193       0.000467   \n",
       "std         0.052916       0.056137       0.013877       0.021594   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type38    Soil_Type39    Soil_Type40  \n",
       "count  565892.000000  565892.000000  565892.000000  \n",
       "mean        0.026233       0.023236       0.014651  \n",
       "std         0.159827       0.150652       0.120152  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From comparing the train and test datasets we get the following conclusions:\n",
    "\n",
    "- Difference between train and test datasets appear to be the last column with the cover type where prediction (y) has to be made\n",
    "- Soil types are not consistent between train and test. Some soil types are unique of train and others only appear in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# <font color=green>2. Data analysis</font>\n",
    "To understand dataframe, let’s look at the data types, the data shape and descriptive statistics.\n",
    "All features are integers. "
   ]
  },
  {
   "attachments": {
    "image-3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## <font color=green>__2.1.Explanation of variables__</font><br>\n",
    "__Elevation__ / quantitative /meters / Elevation in meters <br>\n",
    "__Aspect__ / quantitative / azimuth / Aspect in degrees azimuth <br>\n",
    "\n",
    "<img src=\"Azimuth.png\" width=600 height=200 align=\"center\">\n",
    "\n",
    "__Slope__ / quantitative / degrees / Slope in degrees <br>\n",
    "![image-3.png](attachment:image-3.png)\n",
    "__Horizontal_Distance_To_Hydrology__ / quantitative / meters / Horz Dist to nearest surface water features <br>\n",
    "__Vertical_Distance_To_Hydrology__ / quantitative / meters / Vert Dist to nearest surface water features <br>\n",
    "__Horizontal_Distance_To_Roadways__ / quantitative / meters / Horz Dist to nearest roadway <br>\n",
    "__Hillshade_9am__ / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice <br>\n",
    "__Hillshade_Noon__ / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice <br>\n",
    "__Hillshade_3pm__ / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice <br>\n",
    "\n",
    "<img src=\"Hillshade.png\" width=800 height=200 align=\"center\">\n",
    "\n",
    "__Horizontal_Distance_To_Fire_Points__ / quantitative / meters / Horz Dist to nearest wildfire ignition points <br>\n",
    "__Wilderness_Area (4 binary columns)__ / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation <br>\n",
    "__Soil_Type (40 binary columns)__ / qualitative / 0 (absence) or 1 (presence) / Soil Type designation <br>\n",
    "__Cover_Type (7 types)__ / integer / 1 to 7 / Forest Cover Type designation <br>\n",
    "\n",
    "Source: https://desktop.arcgis.com/en/arcmap/10.3/tools/spatial-analyst-toolbox/how-hillshade-works.htm <br>\n",
    "The wilderness areas are:\n",
    "\n",
    "1 - Rawah Wilderness Area <br>\n",
    "2 - Neota Wilderness Area  <br>\n",
    "3 - Comanche Peak Wilderness Area<br>\n",
    "4 - Cache la Poudre Wilderness Area<br>\n",
    "\n",
    "<img src=\"satellite1.png\" width=1600 height=400 align=\"center\">\n",
    "\n",
    "<img src=\"satellite3.png\" width=1600 height=400 align=\"center\">\n",
    "\n",
    "Source: Google My Maps, own made map based on wilderness area\n",
    "\n",
    "<img src=\"satellite2.png\" width=1600 height=800 align=\"center\">\n",
    "\n",
    "<img src=\"satellite.png\" width=1600 height=800 align=\"center\">\n",
    "\n",
    "Example of Moran soil mapping, source:https://casoilresource.lawr.ucdavis.edu/sde/?series=moran#extent\n",
    "\n",
    "Estimated distance between areas to the centre of each. There is an approximate 25 km distance between nearest areas\n",
    "\n",
    "Based on the book  \"Statistical Methods and Applications in Forestry and Environmental Sciences\" by Chandra et al. (2020), Chapter (Forest Cover-Type Prediction Using Model Averaging) DOI: 10.1007/978-981-15-1476-0, we group the soil types based on the USFS ecological land type units (ELUs), and supplementary provide the details of first digit for climatic zone and second digit for geologic zone of USFS ELU code.\n",
    "\n",
    "The soil types based on USFS ELUs code:<br>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><b>Soil Type</b></th>\n",
    "    <th><b>USFS ELU Code</b></th>\n",
    "    <th><b>Description</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "<td>1  </td>\n",
    "    <td> <b>2702<b></td>\n",
    "      <td> Cathedral family - Rock outcrop complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2  </td>\n",
    "    <td><b><i>2703</i></b> \n",
    "    <td> Vanet - Ratake families complex, very stony</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td><b>2704</b></td>\n",
    "    <td> Haploborolis - Rock outcrop complex, rubbly</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td><b>2705</b> </td>\n",
    "    <td> Ratake family - Rock outcrop complex, rubbly</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td><b>2706</b> </td>\n",
    "    <td> Vanet family - Rock outcrop complex complex, rubbly</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td><b><i>2717</i></b></td>\n",
    "    <td> Vanet - Wetmore families - Rock outcrop complex, stony</td>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td><b>3501</b> </td>\n",
    "    <td> Gothic family</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>8</td>\n",
    "    <td><b>3502</b></td>\n",
    "    <td> Supervisor - Limber families complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>9</td>\n",
    "    <td><b>4201</b> </td>\n",
    "    <td> Troutville family, very stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td><b>4703</b> </td>\n",
    "    <td> Bullwark - Catamount families - Rock outcrop complex, rubbly</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11</td>\n",
    "    <td><b><i>4704</i></b></td>\n",
    "    <td> Bullwark - Catamount families - Rock land complex, rubbly</td>\n",
    "  <tr>\n",
    "    <td>12</td>\n",
    "    <td><b>4744</b> </td>\n",
    "    <td> Legault family - Rock land complex, stony</td> \n",
    "  </tr>\n",
    "  <tr>  \n",
    "    <td>13</td>\n",
    "    <td><b>4758</b> </td>\n",
    "    <td> Catamount family - Rock land - Bullwark family complex, rubbly</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>14</td>\n",
    "    <td><b>5101</b></td>\n",
    "    <td> Pachic Argiborolis - Aquolis complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15</td>\n",
    "    <td><b>5151</b> </td>\n",
    "    <td> unspecified in the USFS Soil and ELU Survey</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>16</td>\n",
    "    <td><b>6101</b> </td>\n",
    "    <td> Cryaquolis - Cryoborolis complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>17</td>\n",
    "    <td><b><i>6102</i></b></td>\n",
    "    <td> Gateview family - Cryaquolis complex</td>\n",
    "  <tr>\n",
    "    <td>18</td>\n",
    "    <td><b>6731</b> </td>\n",
    "    <td> Rogert family, very stony</td>\n",
    "  </tr>\n",
    "  <tr>  \n",
    "    <td>19</td>\n",
    "    <td><b>7101</b> </td>\n",
    "    <td> Typic Cryaquolis - Borohemists complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>20</td>\n",
    "    <td><b>7102</b></td>\n",
    "    <td> Typic Cryaquepts - Typic Cryaquolls complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>21</td>\n",
    "    <td><b>7103</b> </td>\n",
    "    <td> Typic Cryaquolls - Leighcan family, till substratum complex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>22</td>\n",
    "    <td><b>7201</b> </td>\n",
    "    <td> Leighcan family, till substratum, extremely bouldery</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>23</td>\n",
    "    <td><b><i>7202</i></b></td>\n",
    "    <td> Leighcan family, till substratum - Typic Cryaquolls complex</td>\n",
    "  <tr>\n",
    "    <td>24</td>\n",
    "    <td><b>7700</b> </td>\n",
    "    <td> Leighcan family, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>  \n",
    "    <td>25</td>\n",
    "    <td><b>7701</b> </td>\n",
    "    <td> Leighcan family, warm, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>26</td>\n",
    "    <td><b>7702</b></td>\n",
    "    <td> Granile - Catamount families complex, very stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>27</td>\n",
    "    <td><b>7709</b> </td>\n",
    "    <td> Leighcan family, warm - Rock outcrop complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>28</td>\n",
    "    <td><b>7710</b> </td>\n",
    "    <td> Leighcan family - Rock outcrop complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>29</td>\n",
    "    <td><b><i>7745</i></b></td>\n",
    "    <td> Como - Legault families complex, extremely stony</td>\n",
    "  <tr>\n",
    "    <td>30</td>\n",
    "    <td><b>7746</b> </td>\n",
    "    <td> Como family - Rock land - Legault family complex, extremely stony</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>  \n",
    "    <td>31</td>\n",
    "    <td><b>7755</b> </td>\n",
    "    <td> Leighcan - Catamount families complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>32</td>\n",
    "    <td><b>7756</b></td>\n",
    "    <td> Catamount family - Rock outcrop - Leighcan family complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>33</td>\n",
    "    <td><b>7757</b> </td>\n",
    "    <td> Leighcan - Catamount families - Rock outcrop complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>34</td>\n",
    "    <td><b>7790</b> </td>\n",
    "    <td> Cryorthents - Rock land complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>35</td>\n",
    "    <td><b><i>8703</i></b></td>\n",
    "    <td> Cryumbrepts - Rock outcrop - Cryaquepts complex</td>\n",
    "  <tr>\n",
    "    <td>36</td>\n",
    "    <td><b>8707</b> </td>\n",
    "    <td> Bross family - Rock land - Cryumbrepts complex, extremely stony</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>37</td>\n",
    "    <td><b>8708</b> </td>\n",
    "    <td> Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>38</td>\n",
    "    <td><b>8771</b> </td>\n",
    "    <td> Leighcan - Moran families - Cryaquolls complex, extremely stony</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>39</td>\n",
    "    <td><b><i>8772</i></b></td>\n",
    "    <td> Moran family - Cryorthents - Leighcan family complex, extremely stony</td>\n",
    "  <tr>\n",
    "    <td>40</td>\n",
    "    <td><b>8776</b> </td>\n",
    "    <td> Moran family - Cryorthents - Rock land complex, extremely stony</td>\n",
    "\n",
    "Source: https://www.kaggle.com/competitions/forest-cover-type-prediction/data<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"climate_geo.png\" width=600 height=300 align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 56 features with the test set consist of 15120 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 56 columns: the target variable Cover Type and 55 more features to work with. Let's analyze a little bit more each of them to check if we need to clean or preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertical_Distance_To_Hydrology seems to have positive and negative values. Checking the negative values we observed that few are lying on an average altitude of Denver, which is 1500 metres, these values are likely patches bellow a water deposit in the mountain. We should nevertheless apply an absolute conversion to avoid any uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# <font color=green> 3. Exploratory Data Analysis<font> \n",
    "<a id='3.1'></a>    \n",
    "### <font color=green> 3.1. Analysis of the dataset using EDA <font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas profiling gives us the information that the data is formatted and clean: There are no null values and all features are numeric. We have 12 numeric values and 44 Categorial values. \n",
    "The soil and wilderness area are already one-hot-encoded columns.<br>\n",
    "The alert show us that Soiltype 7 and soiltype 15 are always zero. And there are several highly correlated features as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "report = ProfileReport(data_train, minimal=False)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __ID__: As unique values, consider dropping it from the analysis.<br>\n",
    "* __Elevation__: Has very few values above 3500meters, which makes sense as the higher the altitude the less tree grow there.<br>\n",
    "* __Aspect__: Has high correlation with the Hillshade variables<br>\n",
    "* __Slope__: Has high correlation with the Hillshade variables, there seem to be values outside the norm around 25degrees<br>\n",
    "* __Cover_Type__: Cover Type are equal distributed, each Cover Type are represented in an equally.<br>\n",
    "* __Soil_Type15__ and __Soil_Type7__: No values, consider removing them but first check if these are also exist in the testing data to confirm our thought. <br>\n",
    "* __Soil_Type28,36,25,9 and 8__: Very few values, seems to be rather scare soil types. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the Soil_Type 15 and Soil_Type7 should be removed based on the test data. Since both do exist with values in the test set, we cannot test these as these do not exist in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Soil_Type15'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Soil_Type7'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical variables seem to not be normal distributed. All variables though are not normal distributed.\n",
    "\n",
    "To ascertain this, we will use the statistical D'Agostino and Pearson's test below. The following conclusions are made:\n",
    "\n",
    "- All features are more skewed.   \n",
    "- The features that measure distance are positively skewed. \n",
    "- Hillshade 9 am and Noon has a similar left-skewed distribution. \n",
    "- None of the features follow a normal distribution, which is confirmed by the statistical Shapiro test for normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a> \n",
    "### <font color=green> 3.2. D'Agostino and Pearson's Test <font> \n",
    "The numerical variables seem to not be normal distributed in the Pandas Profiling Report. However we will test this with the Shapiro test below and it confirms the initial analysis that the features do not follow a Gaussian Distribution at a significance level of 95%. All features are skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'Agostino and Pearson's Test\n",
    "from scipy.stats import normaltest\n",
    "alpha = 0.05\n",
    "for i in (['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']):\n",
    "    print ()\n",
    "    print (i)\n",
    "    stat, p = normaltest(data_train[[i]])\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    if p > alpha:\n",
    "        print('The data follows Gaussian Distribution (fail to reject H0)')\n",
    "    else:\n",
    "        print('The data does not follow Gaussian Distribution  (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a> \n",
    "### <font color=green>3.3.Checking Variable Completeness <font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for completeness of Wilderness data. Since Wilderness is One Hot Encoded, we want to check if all the values sum up to 15120 or if we have values which are entered as zero or even 1, meaning the values are entered twice in two different Wilderness. \n",
    "\n",
    "The below show that the values are all together sum up to 15120, which shows us the completeness of the Wilderness area and uniqueness of the wilderness area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.iloc[:,11:15].sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the Soil, we check if the data is adding up to 15120 to see if there are values entered as zero and actually give us missing information. \n",
    "\n",
    "Similarly, the data is complete and there are no entered values with zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.iloc[:,15:55].sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a> \n",
    "### <font color=green>3.4.Correlation Matrix <font> \n",
    "Looking at the features which are highly correlated with a threshold above 0.5: <br>\n",
    "* __Vertical_Distance_To_Hydrology__ positivly correlated to __Horizontal_Distance_To_Hydrology__ <br>\n",
    "* __Horizontal_Distance_To_Roadways__ positivly correlated to __Elevation__  <br>\n",
    "* __Hillshade_9am__ negativly correlated and __Hillshade_3pm__ positivly correlated to __Aspect__<br>\n",
    "* __Hillshade_Noon__ negativly correlated to __Slope__<br>\n",
    "* __Hillshade variables__ are also correlated between themselves,but Hillshade 3pm and Hillshade 9am are negative correlated <br>\n",
    "* __Wilderness Area 4__ is highly correlated with Elevation <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap \n",
    "matrix = data_train.corr()\n",
    "mask = np.zeros_like(matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(120,60))\n",
    "heatmap = sns.heatmap(matrix, center=0, fmt=\".2f\", square=True, annot=True, linewidth=.9, mask = mask,vmax=.7);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix [\"Vertical_Distance_To_Hydrology\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix [\"Elevation\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix [\"Hillshade_9am\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix [\"Wilderness_Area4\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing reverse One Hot Encoding using Pandas idxmax ( variables used for EDA and Data analysis only)\n",
    "# With this, we make later EDA statistics\n",
    "\n",
    "data_train['Wilderness'] = (data_train.iloc[:, 11:15] == 1).idxmax(1)\n",
    "data_train['Soil'] = (data_train.iloc[:, 15:56] == 1).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Cover_Type1'] = data_train['Cover_Type'].replace([1,2,3,4,5,6,7],['Spruce/Fir','Lodgepole Pine','Ponderosa Pine','Cottonwood/Willow','Aspen','Douglas-fir','Krummholz'])\n",
    "data_train['Wilderness'] = data_train['Wilderness'].replace(['Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4'],['Rawah Wilderness Area ','Neota Wilderness Area','Comanche Peak Wilderness Area','Cache la Poudre Wilderness Area'])\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Wilderness'] = (data_test.iloc[:, 11:15] == 1).idxmax(1)\n",
    "data_test['Soil'] = (data_test.iloc[:, 15:56] == 1).idxmax(1)\n",
    "data_test['Wilderness'] = data_test['Wilderness'].replace(['Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4'],['Rawah Wilderness Area ','Neota Wilderness Area','Comanche Peak Wilderness Area','Cache la Poudre Wilderness Area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.5'></a> \n",
    "### <font color=green>3.5.Paired density, scatterplot matrix and 3D Graphics <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In seaborn we can observe the following:<br>\n",
    "* Elevation differentiate the cover types very well \n",
    "* Slope, almost all Cover Types overlap \n",
    "* very skewed distribtutions of Horizontal/Vertical Distance to Hydrology, Horizontal Distance to Roadways and firepoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "g = sns.PairGrid(data_train, vars = ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points'],hue='Cover_Type1', diag_sharey=False, palette = 'rainbow_r')\n",
    "g.map_upper(sns.scatterplot, s=15)\n",
    "g.map_lower(sns.kdeplot,warn_singular=False)\n",
    "g.map_diag(sns.kdeplot, lw=2,warn_singular=False)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "g = sns.PairGrid(data_train, vars = ['Hillshade_9am','Hillshade_Noon','Hillshade_3pm'],hue='Cover_Type1', diag_sharey=False, palette = 'rainbow_r')\n",
    "g.map_upper(sns.scatterplot, s=15)\n",
    "g.map_lower(sns.kdeplot,warn_singular=False)\n",
    "g.map_diag(sns.kdeplot, lw=2,warn_singular=False)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the values in the test set \n",
    "\n",
    "#COMMENTED OUT AS NOTEBOOK DIES HERE (PEDRO)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "g = sns.PairGrid(data_test, vars = ['Hillshade_9am','Hillshade_Noon','Hillshade_3pm'], diag_sharey=False, palette = 'rainbow_r')\n",
    "g.map_upper(sns.scatterplot, s=15)\n",
    "g.map_lower(sns.kdeplot,warn_singular=False)\n",
    "g.map_diag(sns.kdeplot, lw=2,warn_singular=False)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hillshade 3pm  have some null values and looking at the graphical distribution it seems more these are missing values as these do not follow the pattern of the graph. \n",
    "\n",
    "- But looking at the Hilshade noon and hilshade 9am it looks  these are not null in their case. \n",
    "\n",
    "- Since Hilshade 9am and Hilshade 3pm are negativly correlated, we can impute the values based on the correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "temp_df = data_train[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].copy()\n",
    "temp_df['Cover_Type'] = [label_names[i-1] for i in data_train['Cover_Type']]\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    temp_df, \n",
    "    x='Hillshade_9am', \n",
    "    y='Hillshade_Noon', \n",
    "    z='Hillshade_3pm',\n",
    "    color='Cover_Type',\n",
    "    title='Hillshade Features in 3-D',\n",
    "    opacity=0.2, \n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly[:7],\n",
    "    width=1000, height=800\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "temp_df = data_train[['Slope', 'Elevation', 'Aspect']].copy()\n",
    "temp_df['Cover_Type'] = [label_names[i-1] for i in data_train['Cover_Type']]\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    temp_df, \n",
    "    x='Slope', \n",
    "    y='Elevation', \n",
    "    z='Aspect',\n",
    "    color='Cover_Type',\n",
    "    title='Hillshade Features in 3-D',\n",
    "    opacity=0.2, \n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly[:7],\n",
    "    width=1000, height=800\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "temp_df = data_train[['Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Horizontal_Distance_To_Hydrology']].copy()\n",
    "temp_df['Cover_Type'] = [label_names[i-1] for i in data_train['Cover_Type']]\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    temp_df, \n",
    "    x='Horizontal_Distance_To_Roadways', \n",
    "    y='Horizontal_Distance_To_Fire_Points', \n",
    "    z='Horizontal_Distance_To_Hydrology',\n",
    "    color='Cover_Type',\n",
    "    title='Hillshade Features in 3-D',\n",
    "    opacity=0.2, \n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly[:7],\n",
    "    width=1000, height=800\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.6'></a>\n",
    "### <font color=green>__3.6.Categorial EDA__</font><br>\n",
    "\n",
    "<a id='3.6.1'></a>\n",
    "#### <font color=green>__3.6.1.Categorial Bar Diagrams__</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Area1__ has four dominant Cover types: Mainly Lodgepole Pine, Spruce/Fir, Aspen and bit Krummholz. <br>\n",
    "- __Area2__ has three Cover Types but are small in numbers: Krummholz, Spruce/Fir and Lodgepole Pine. <br>\n",
    "-  __Area3__ has six Cover Types in decreasing order Krummholz, Aspen, Douglas-fir, Lodgepole Pine, Spruce/Fir and Ponderosa Pine.<br>\n",
    "-  __Area4__ has four dominant Cover types in decreasing order: Cottonwood/Willow, Ponderosa Pine, Douglas-fir and Lodgepole Pine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking attributes one more time\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Changed Wilderness for Cover_Type as I got an error, did you do feature engineering prior to this step_?\n",
    "sns.catplot(y=\"Wilderness\", hue='Cover_Type1', kind=\"count\",\n",
    "            palette='rainbow_r', edgecolor=\".6\",\n",
    "            data = data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlights only: \n",
    "There are few Soil Types where there are few Cover Types or not existing cover Types, most of them are stony soil types like Soil Types 18,24,5,9,28,34,37,36,26,27 and 25. Few are from other soil types like 16,20,19,8 and 21. <br>\n",
    "__Soil_Type3__ (Haploborolis - Rock outcrop complex, rubbly) : Mainly Cover Type __Cottonwood__ <br>\n",
    "__Soil_Type4__ (Ratake family - Rock outcrop complex, rubbly) :__Ponderosa Pine__ <br>\n",
    "__Soil_Type10__ (Bullwark - Catamount families - Rock outcrop complex, rubbly): Mainly __Douglas-fir and Ponderosa Pine__ <br>\n",
    "__Soil_Type23__ (Leighcan family, till substratum - Typic Cryaquolls complex): Mainly __Spruce/Fir__<br>\n",
    "__Soil_Type29__ (Como - Legault families complex, extremely stony) : __Lodgepole Pine, Spruce/Fir__<br>\n",
    "__Soil_Type30__ (Como family - Rock land - Legault family complex, extremely stony): __Aspen__<br>\n",
    "__Soil_Type38__ (Leighcan - Moran families - Cryaquolls complex, extremely stony): Mainly __Krummholz__<br>\n",
    "__Soil_Type39__ (Moran family - Cryorthents - Leighcan family complex, extremely stony): Mainly __Krummholz__<br>\n",
    "__Soil_Type40__ (Moran family - Cryorthents - Rock land complex, extremely stony): Mainly __Krummholz__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_dummies = data_train.loc[:,data_train.columns.str.startswith('Soil_Type')]\n",
    "soil = soil_dummies.idxmax(axis=1)\n",
    "soil.name = 'Soil'\n",
    "data_train['Soil'] = soil\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x='Soil',data=data_train,palette='rainbow',order = data_train['Soil'].value_counts().index);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.catplot(y=\"Soil\", hue='Cover_Type1', kind=\"count\",\n",
    "            palette='rainbow_r', edgecolor=\".6\",\n",
    "            data=data_train,height=30, aspect=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.6.2'></a>\n",
    "#### <font color=green>__3.6.2.Violinplot with Dependent Variable__</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violinplot shows the distribution of the Cover_Types against the numerical variables: \n",
    "\n",
    "1. __Spruce/Fir__: \n",
    "    - Slope is lower <br>\n",
    "    \n",
    "2. __Lodgepole Pine__: \n",
    "    - Slope is lower <br>\n",
    "    \n",
    "3. __Ponderosa Pine__: \n",
    "    - Closer to the road than other cover types<br>\n",
    "    \n",
    "4. __Cottonwood/Willow__:\n",
    "    - Closer to the road than other cover types\n",
    "    - Found on lower elevation\n",
    "    - Lowest horizontal distance to hydrology is lower and less spread than the other coverTypes\n",
    "    - Vertical distance to hydrology is more above the sea level than below, Hildshade 9am is high<br>\n",
    "    \n",
    "5. __Aspen__: \n",
    "    - Hildshade 9am is high <br>\n",
    "    \n",
    "6. __Douglas-fir__: \n",
    "    - Closer to the road than other cover types, Hildshade 9am is very spread<br>\n",
    "    \n",
    "7. __Krummholz__: \n",
    "    - Found on higher elevation, Slope is lower <br>\n",
    "\n",
    "* Elevation has the highest variance among the different Cover_Types\n",
    "* Aspect on the other hand is fairly equally spread among the different Cover_Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars= ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology']\n",
    "fig, axs = plt.subplots(1, len(vars), figsize=(25,5))\n",
    "for i in range(0,len(vars)):\n",
    "    sns.violinplot( y=data_train[vars[i]],x=data_train['Cover_Type1'], data=data_train,ax=axs[i],palette = 'rainbow_r')\n",
    "    for tick in axs[i].get_xticklabels():\n",
    "        tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars= ['Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']\n",
    "fig, axs = plt.subplots(1, len(vars)-1, figsize=(25,5))\n",
    "for i in range(0,len(vars)-1):\n",
    "    sns.violinplot( y=data_train[vars[i]],x=data_train['Cover_Type1'], data=data_train,ax=axs[i],palette = 'rainbow_r')\n",
    "    for tick in axs[i].get_xticklabels():\n",
    "        tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.6.3'></a>\n",
    "#### <font color=green>__3.6.3.Treemap for categorial Data__</font><br>\n",
    "In order to see the distribution of the treemap features we are checking which features are more represented than others.<br>\n",
    "You can see on the Soil Type that Soil Type 10 is represented the most, than Soil Type 29 and then Soil Type 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treemap Graph by Soil Type on the Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Treemap graph\n",
    "\n",
    "df = data_train.groupby('Soil').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,20), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8,text_kwargs={'fontsize':13})\n",
    "\n",
    "# Decorate\n",
    "plt.title('Treemap Native Country - Train ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treemap Graph by Soil Type on the Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_test.groupby('Soil').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,20), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8,text_kwargs={'fontsize':13})\n",
    "\n",
    "# Decorate\n",
    "plt.title('Treemap Native Country - Train ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "df = data_train.groupby('Wilderness').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,20), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8,text_kwargs={'fontsize':13})\n",
    "\n",
    "# Decorate\n",
    "plt.title('Treemap Native Country - Train ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Wilderness Area: Wilderness Area 3 is highly represented (42%), then Area 4 (31%) , Area 1 (24%) and Area 2 (3%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the test data for the same wilderniss area as an comparision if the distribution is similar on wilderness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "df = data_test.groupby('Wilderness').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,20), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8,text_kwargs={'fontsize':13})\n",
    "\n",
    "# Decorate\n",
    "plt.title('Treemap Native Country - Train ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already seen in the Pandas Profiling Report Cover Type is equally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly, can we see by wilderness area what are the predominant cover types? That way we can start making an association with the type of soil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "df = data_train.groupby('Cover_Type1').size().reset_index(name='counts')\n",
    "labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "sizes = df['counts'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,20), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8,text_kwargs={'fontsize':13})\n",
    "\n",
    "# Decorate\n",
    "plt.title('Treemap Native Country - Train ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.treemap(data_train, path=[px.Constant(\"all\"), 'Cover_Type1', 'Wilderness'])\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.treemap(data_train, path=[px.Constant(\"all\"), 'Cover_Type1', 'Wilderness','Soil'])\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# <font color=green> 4.Baseline dataset <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic benchmark without deploying any feature engineering. The dataset without any modifications is used to use as a Baseline Model for future improvements. In addition we use only basic Hyperparameters and did not fine tune these in the Baseline model as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.0'></a>\n",
    "## <font color=green>  0.Prepare Data and Standardization<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign y and drop irrelevant features for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_train.drop(labels=['Id','Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y=data_train['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms don't perform well when the input numerical attributes have very different scales. Since we have very skewed data, standardization is much less affected by outliers. The scale mean is zero and the standardization is 1.  Also important we do not scale dummy variables, since these are 0 and 1, we leave them out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X[scale_numerical]=scaler.fit_transform(X[scale_numerical])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do an additional split on the train dataset (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take for the Baseline model the exact same random state seed of 18. Since the train set was not random and the cover types were equally spread, we stratify the splitt of the train into a train and validation set and what to keep the balanced dataset with stratification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split (X,y,random_state=37,stratify=y) #seed is 18!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the distribution of the cover types to ensure they are balanced among both train and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model on the subsplit train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## <font color=green>  1.Random Forest<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline score with random forest 20 on original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test set\n",
    "y_pred_test_forest = forest.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrices below, the rows represent the true labels and the columns represent predicted labels. Values on the diagonal represent the % of times where the predicted label matches the true label. Values in all other cells represent instances where the classifier mislabeled an observation; the column tells us what has been predicted, and the row tells us the correct predicted labels, which you can see on the diagonal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_test_forest)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Precision__:Correctly-identified number of classes divided by the model predicted classes. In case of Spur/Fir (1), the precision score is low. Meaning that the number of correctly -identified Spur/Fir divided by all correct or wrong predicted Spur/Fir (TP/(TP+FP))<br>\n",
    "__Recall__(Sensitivity,True Positive Rate): The ratio of correct positive predictions to the total positive examples (TP/(TP+FN)). For Spur/Fir the number of actual Spur/Fir that the prediction classified correctly as such. <br>\n",
    "__F1-score__: Measures of a model accuracy on a dataset. It combines precision and recall and can tell you if the model is good. The aim is to get close to 1. As you can see it is very low for Spur/Fir<br>\n",
    "__Accuracy__: Ratio of correctly predicted examples by the total examples. (TP+TN)/(TP+TN+FP+FN) which is 84% <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred_test_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "visualizer = ClassPredictionError(\n",
    "    model_forest, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_curve(model, X_train,y_train, X_val, y_val):\n",
    "\n",
    "    # Creating visualization with the readable labels\n",
    "    visualizer = ROCAUC(model, encoder={1: 'Spruce/Fir', \n",
    "                                        2: 'Lodgepole Pine', \n",
    "                                        3: 'Ponderosa Pine',\n",
    "                                       4: 'Cottonwood/Willow',\n",
    "                                       5: 'Aspen',\n",
    "                                       6: 'Douglas-fir',\n",
    "                                       7: 'Krummholz'})\n",
    "\n",
    "                                        \n",
    "    # Fitting to the training data first then scoring with the test data                                    \n",
    "    visualizer.fit(X_train,y_train)\n",
    "    visualizer.score(X_val, y_val)\n",
    "    visualizer.show()\n",
    "    \n",
    "    return visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/swlh/how-to-create-an-auc-roc-plot-for-a-multiclass-model-9e13838dd3de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_forest, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.statology.org/plot-multiple-roc-curves-python/ <br>\n",
    "https://afioto.medium.com/classification-visualizations-with-yellowbrick-d6f6150d7a32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying model in test dataset (data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorial variables of test that we added earlier for EDA needs to be removed as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=forest.predict(data_test.drop(labels=['Id','Wilderness','Soil'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame(data=pred,columns=['Cover_Type'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinpoint ID to prediction in data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Id']=data_test['Id']\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## <font color=green> 2.Gradient Boosting<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check convention for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=1, max_features=2, max_depth=2, random_state=0)\n",
    "model_gb = gb_clf2.fit(X_train, y_train)\n",
    "y_pred_test_gb = gb_clf2.predict(X_val)\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, y_pred_test_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_test_gb)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "visualizer = ClassPredictionError(\n",
    "    model_gb, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_gb, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## <font color=green>  3.Decision Trees<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=18)\n",
    "model_tree = tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr = tree.predict(X_train)\n",
    "y_pred_ts = tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_ts)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(y_train, y_pred_tr))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(y_val, y_pred_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
    "visualizer = ClassPredictionError(\n",
    "    model_tree, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_tree, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline with decision trees (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(tree, X_train, y_train, cv=10, scoring='accuracy')\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.4'></a>\n",
    "## <font color=green> 4.K-Nearest Neighbors (KNN)<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "model_knn = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr_knn = knn.predict(X_train)\n",
    "y_pred_ts_knn = knn.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_ts_knn)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(y_train, y_pred_tr_knn))\n",
    "print(\"\\nTesting Results:\\n\")\n",
    "print(classification_report(y_val, y_pred_ts_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "visualizer = ClassPredictionError(\n",
    "    model_knn, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_knn, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_knn = pd.DataFrame(data=pred,columns=['Cover_type'])\n",
    "test_id = data_test['Id']\n",
    "submission_knn['id'] = test_id\n",
    "submission_knn.set_index('id',inplace=True)\n",
    "submission_knn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/<br>\n",
    "https://towardsdatascience.com/are-you-solving-ml-clustering-problems-using-k-means-68fb4efa5469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.5'></a>\n",
    "## <font color=green> 5.Logistic Regression<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# define the multinomial logistic regression model\n",
    "log = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(log, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr_log = log.predict(X_train)\n",
    "y_pred_ts_log = log.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(classification_report(y_val, y_pred_ts_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_ts_log)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "visualizer = ClassPredictionError(\n",
    "    model_log, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_log, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.6'></a>\n",
    "## <font color=green> 6.Naive Bayes<font>\n",
    "Naive Bayes models are a group of extremely fast and simple classification algorithms that are often suitable for very high-dimensional datasets. Because they are so fast and have so few tunable parameters, they end up being very useful as a quick-and-dirty baseline for a classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "bayes = GaussianNB()\n",
    "model_bayes = bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr_bayes = bayes.predict(X_train)\n",
    "y_pred_ts_bayes = bayes.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred_ts_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val, y_pred_ts_bayes)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "visualizer = ClassPredictionError(\n",
    "    model_bayes, palette = 'rainbow_r')\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_val, y_val)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(model_bayes, X_train,y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# <font color=green> Model Comparison <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes). Since we do not have a inbalance of classes and all classes are evently distributed we can use the macro-average, which are equal to the micro-average of all algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work it out in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th><b>Algorithms</b></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precision</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "<td>Random Forest  </td>\n",
    "    <td> <b>0.84<b></td>\n",
    "      <td> 0.84</td>\n",
    "      <td> 0.85</td>\n",
    "      <td> 0.84</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Gadient Boosting  </td>\n",
    "    <td><b><i>0.67</i></b> \n",
    "    <td> 0.67</td>\n",
    "    <td> 0.67</td>\n",
    "    <td> 0.66</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Decision Trees</td>\n",
    "    <td><b>0.78</b></td>\n",
    "    <td> 0.78</td>\n",
    "    <td> 0.78</td>\n",
    "    <td> 0.78</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>K- Nearest Neighbors(KNN)</td>\n",
    "    <td><b>0.78</b> </td>\n",
    "    <td> 0.79</td>\n",
    "    <td> 0.78</td>\n",
    "    <td> 0.78</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Logistic Regression</td>\n",
    "    <td><b>0.72</b> </td>\n",
    "    <td> 0.72</td>\n",
    "    <td> 0.72</td>\n",
    "    <td> 0.72</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Naive Bayes</td>\n",
    "    <td><b>0.48</b> </td>\n",
    "    <td> 0.57</td>\n",
    "    <td> 0.48</td>\n",
    "    <td> 0.39</td>\n",
    "  </tr>     \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Our best model is __Random Forest__, so this will be our baseline model to compare with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to make it in python but doesnt work, check"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# <font color=green> 3.Feature Engineering <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> 3.1 Check for Anomalies and Outliers <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the z-score is sensitive to the  mean and standard deviation and its assumption of a normally distributed variable, we cannot use the z-score for outlier handleing because of the skewed data. The disadvantage using percentile it consoders always and outlier of the lowest or highest value, even there are no outliers. As the number of observations increases, so does the number of observations considered outliers; After all, using a percentile based method will always flat-out reject a certain percentage of our observations.Thus, we need to use the percentile with care. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection Treatment using Inter-Quartile Range rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IQR is the difference between the 75th and 25th percentile. The IQR is more resistant to outliers. The IQR by definition only covers the middle 50% of the data, so outliers are well outside this range and the presence of a small number of outliers is not likely to change this significantly. If you add an outlier, the IQR will change to another set of data points that are probably not that dissimilar to the previous ones (in most datasets), hence it is “resistant” to change. This is especially the case of a large dataset.\n",
    "\n",
    "Now we are testing different ranges for IQR, namely 2,3 and 4 to check for more extreme outlier values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_function(df, col_name,value_IQR):\n",
    "    ''' this function detects first and third quartile and interquartile range for a given column of a dataframe\n",
    "    then calculates upper and lower limits to determine outliers conservatively\n",
    "    returns the number of lower and uper limit and number of outliers respectively\n",
    "    '''\n",
    "    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "                      \n",
    "    upper_limit = third_quartile+(value_IQR*IQR)\n",
    "    lower_limit = first_quartile-(value_IQR*IQR)\n",
    "    outlier_count = 0\n",
    "                      \n",
    "    for value in df[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "    return lower_limit, upper_limit, outlier_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Quartile Range rule: 4 IQR from Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all columns to see if there are any outliers, for all values which are not only 0 and 1\n",
    "for column in [\"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\"Horizontal_Distance_To_Fire_Points\"]:\n",
    "    if outlier_function(data_train, column,4)[2] > 0:\n",
    "        print(\"There are {} outliers in {}\".format(outlier_function(data_train, column,4)[2], column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 1 record of Hillshade_9am with a zero value, which is a valid value as Hillshade can be zero. Hence we keep the value as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers and testing baseline model\n",
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data_train['Vertical_Distance_To_Hydrology'], 25), percentile(data_train['Vertical_Distance_To_Hydrology'], 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 4\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# remove outliers\n",
    "data_train_vd_h = data_train[(data_train['Vertical_Distance_To_Hydrology'] > lower) & (data_train['Vertical_Distance_To_Hydrology'] < upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model improves after removing vertical distance to hydrology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=data_train_vd_h.drop(labels=['Id','Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y4=data_train_vd_h['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X4[scale_numerical]=scaler.fit_transform(X4[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train,X4_val,y4_train,y4_val = train_test_split(X4,y4,random_state=37) #seed is 18!Cannot use stratify because the datset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X4_train,y4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the previous score with the new score after removing the outliers of vertical distance to Hydrology: previous __forest.score: 0.83968__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy_score\n",
    "forest.score(X4_val,y4_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing with Median__<br>\n",
    "Since it improved our performance of our model, I would still use median values to keep a balanced sample set otherwise the data becomes unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = np.median(data_train['Vertical_Distance_To_Hydrology'])\n",
    "for i in data_train['Vertical_Distance_To_Hydrology']:\n",
    "    if i > upper or i < lower:\n",
    "            data_train['Vertical_Distance_To_Hydrology_n'] = data_train['Vertical_Distance_To_Hydrology'].replace(i, med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmed=data_train.drop(labels=['Id','Cover_Type','Wilderness','Cover_Type1','Soil','Vertical_Distance_To_Hydrology'],axis=1)\n",
    "ymed=data_train['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology_n',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "Xmed[scale_numerical]=scaler.fit_transform(Xmed[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmed_train,Xmed_val,ymed_train,ymed_val = train_test_split(X4,y4,random_state=37) #seed is 18!Cannot use stratify because the datset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(Xmed_train,ymed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy_score\n",
    "forest.score(Xmed_val,ymed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Quartile Range rule: 3 IQR from Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all columns to see if there are any outliers, for all values which are not only 0 and 1\n",
    "for column in [\"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\"Horizontal_Distance_To_Fire_Points\"]:\n",
    "    if outlier_function(data_train, column,3)[2] > 0:\n",
    "        print(\"There are {} outliers in {}\".format(outlier_function(data_train, column,3)[2], column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers and testing baseline model\n",
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data_train['Horizontal_Distance_To_Hydrology'], 25), percentile(data_train['Horizontal_Distance_To_Hydrology'], 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 3\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# remove outliers\n",
    "data_train_hd_h3 = data_train[(data_train['Horizontal_Distance_To_Hydrology'] > lower) & (data_train['Horizontal_Distance_To_Hydrology'] < upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_hd=data_train_hd_h3.drop(labels=['Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y3_hd=data_train_hd_h3['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X3_hd[scale_numerical]=scaler.fit_transform(X3_hd[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hd,X_val_hd,y_train_hd,y_val_hd = train_test_split (X3_hd,y3_hd,random_state=37) #seed is 18!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train_hd,y_train_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_val_hd,y_val_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vertical_Distance_To_Hydrology__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers and testing baseline model\n",
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data_train['Vertical_Distance_To_Hydrology'], 25), percentile(data_train['Vertical_Distance_To_Hydrology'], 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 3\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# remove outliers\n",
    "data_train_vd_h3 = data_train[(data_train['Vertical_Distance_To_Hydrology'] > lower) & (data_train['Vertical_Distance_To_Hydrology'] < upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=data_train_vd_h3.drop(labels=['Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y3=data_train_vd_h3['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X3[scale_numerical]=scaler.fit_transform(X3[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split (X3,y3,random_state=37) #seed is 18!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement from previous removal of outliers of Vertical Distance to Hydrology is not so incremental anymore in addition we would remove several points in the dataset, we will disregard this option of the 49 datapoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy_score\n",
    "forest.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Horizontal_Distance_To_Roadways__<br>\n",
    "Taking out the outliers of roadways does not improve the model it actually gets worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers and testing baseline model\n",
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data_train['Horizontal_Distance_To_Roadways'], 25), percentile(data_train['Horizontal_Distance_To_Roadways'], 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 3\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# remove outliers\n",
    "data_train_rw = data_train[(data_train['Horizontal_Distance_To_Roadways'] > lower) & (data_train['Horizontal_Distance_To_Roadways'] < upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_rw=data_train_rw.drop(labels=['Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y3_rw=data_train_rw['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X3_rw[scale_numerical]=scaler.fit_transform(X3_rw[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split (X3_rw,y3_rw,random_state=37) #seed is 18!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy_score\n",
    "forest.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Horizontal_Distance_To_Fire_Points__<br>\n",
    "Taking out the outliers of roadways does not improve the model it actually gets worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers and testing baseline model\n",
    "# calculate interquartile range\n",
    "from numpy import percentile\n",
    "q25, q75 = percentile(data_train['Horizontal_Distance_To_Fire_Points'], 25), percentile(data_train['Horizontal_Distance_To_Fire_Points'], 75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 3\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# remove outliers\n",
    "data_train_fp = data_train[(data_train['Horizontal_Distance_To_Fire_Points'] > lower) & (data_train['Horizontal_Distance_To_Fire_Points'] < upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_fp=data_train_fp.drop(labels=['Cover_Type','Wilderness','Cover_Type1','Soil'],axis=1)\n",
    "y3_fp=data_train_fp['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_numerical =['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points']\n",
    "scaler = StandardScaler()\n",
    "X3_fp[scale_numerical]=scaler.fit_transform(X3_fp[scale_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split (X3_fp,y3_fp,random_state=37) #seed is 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy_score\n",
    "forest.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "vars = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology']\n",
    "fig = make_subplots(rows=1, cols=len(vars))\n",
    "for i, var in enumerate(vars):\n",
    "    fig.add_trace(\n",
    "        go.Box(y=data_train[var],\n",
    "        name=var),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_traces(boxpoints='all', jitter=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "vars = ['Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points']\n",
    "fig = make_subplots(rows=1, cols=len(vars))\n",
    "for i, var in enumerate(vars):\n",
    "    fig.add_trace(\n",
    "        go.Box(y=data_train[var],\n",
    "        name=var),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_traces(boxpoints='all', jitter=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "vars = ['Hillshade_9am', 'Hillshade_Noon']\n",
    "fig = make_subplots(rows=1, cols=len(vars))\n",
    "for i, var in enumerate(vars):\n",
    "    fig.add_trace(\n",
    "        go.Box(y=data_train[var],\n",
    "        name=var),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_traces(boxpoints='all', jitter=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hillshade outliers are legitimite as zero means there is no sunlight, thus we will keep the values of zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green> Feature engineering of the features <font>\n",
    "#### <font color=green> Drop ID as it has unique value <font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We agree for the test to not remove ID!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop('Id',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Distance To Hydrology <font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine Vertical distance to Hydrology and Horizontal distance to Hydrology since these two are highly correlated and also we can transform it into one variable which would give the distance to the closest water surface and using Pythagoras \n",
    "theorem for Distance calculation, since we have the horizontal and the vertical Distance. \n",
    "Source : https://towardsdatascience.com/types-of-transformations-for-better-normal-distribution-61c22668d3b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Distance_To_Hydrology'] = data_train['Horizontal_Distance_To_Hydrology']**2 +data_train['Vertical_Distance_To_Hydrology']**2\n",
    "data_train['Distance_To_Hydrology'] = data_train['Distance_To_Hydrology']**0.5\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are checking the distribution of the new created variable if further transformation is needed. The Distance to Hydrology is still positive skewed and has zero values. In order to use log we will use log + 1 in oder to use logarithm with zero values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['Distance_To_Hydrology'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Distance_To_Hydrology'].min(),\n",
    "      \"\\nmax\\n\", data_train['Distance_To_Hydrology'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Distance_To_Hydrology'], hist = True, fit = norm, color='green',kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log10_Distance_To_Hydrology'] = np.log10(data_train['Distance_To_Hydrology']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['sqr_Distance_To_Hydrology'] = data_train['Distance_To_Hydrology']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['log10_Distance_To_Hydrology'], hist = True, fit = norm,color = 'orange', kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['log10_Distance_To_Hydrology'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log10_Distance_To_Hydrology'].min(),\n",
    "      \"\\nmax\\n\", data_train['log10_Distance_To_Hydrology'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['sqr_Distance_To_Hydrology'], hist = True, color= 'darkgreen', fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['sqr_Distance_To_Hydrology'].skew(), \n",
    "      \"\\nmin\\n\", data_train['sqr_Distance_To_Hydrology'].min(),\n",
    "      \"\\nmax\\n\", data_train['sqr_Distance_To_Hydrology'].max(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, for distance to Hydrology the square root showed a better performance in terms of skewness and is closer to a normal bell shaped than the logarithm transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Horizontal Distance To Roadways <font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For log transformation there should be no zeros, negative values and the distribution should be positive skwed( bigger than 1 is positive) hence we are using the square root \n",
    "\n",
    "https://www.youtube.com/watch?v=_c3dVTRIK9c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['Horizontal_Distance_To_Roadways'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Horizontal_Distance_To_Roadways'].min(),\n",
    "      \"\\nmax\\n\", data_train['Horizontal_Distance_To_Roadways'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Horizontal_Distance_To_Roadways'], hist = True, fit = norm, color='green', kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Sqr_Horizontal_Distance_To_Roadways'] = data_train['Horizontal_Distance_To_Roadways']**0.5\n",
    "data_train['log_Horizontal_Distance_To_Roadways'] = np.log(data_train['Horizontal_Distance_To_Roadways']+1)\n",
    "data_train['log10_Horizontal_Distance_To_Roadways'] = np.log10(data_train['Horizontal_Distance_To_Roadways']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['Sqr_Horizontal_Distance_To_Roadways'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Sqr_Horizontal_Distance_To_Roadways'].min(),\n",
    "      \"\\nmax\\n\", data_train['Sqr_Horizontal_Distance_To_Roadways'].max(),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Sqr_Horizontal_Distance_To_Roadways'], hist = True, color= 'darkgreen', fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['log_Horizontal_Distance_To_Roadways'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log_Horizontal_Distance_To_Roadways'].min(),\n",
    "      \"\\nmax\\n\", data_train['log_Horizontal_Distance_To_Roadways'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['log_Horizontal_Distance_To_Roadways'], hist = True,color = 'orange', fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log_log_Horizontal_Distance_To_Roadways'] = np.log(data_train['log_Horizontal_Distance_To_Roadways']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['log_log_Horizontal_Distance_To_Roadways'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log_log_Horizontal_Distance_To_Roadways'].min(),\n",
    "      \"\\nmax\\n\", data_train['log_log_Horizontal_Distance_To_Roadways'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew\\n\", data_train['log10_Horizontal_Distance_To_Roadways'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log10_Horizontal_Distance_To_Roadways'].min(),\n",
    "      \"\\nmax\\n\", data_train['log10_Horizontal_Distance_To_Roadways'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['log10_Horizontal_Distance_To_Roadways'], hist = True, color = 'orange',fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaltest(data_train['log10_Horizontal_Distance_To_Roadways'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved the best result for square root of the Horizontal Distance to Roadways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Slope <font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['Slope'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Slope'].min(),\n",
    "      \"\\nmax\\n\", data_train['Slope'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Slope'], hist = True, fit = norm, kde = True,  color='green',kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['logSlope'] = np.log(data_train['Slope']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew after transformation\\n\", data_train['logSlope'].skew(), \n",
    "      \"\\nmin\\n\", data_train['logSlope'].min(),\n",
    "      \"\\nmax\\n\", data_train['logSlope'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['SqrSlope'] = data_train['Slope']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew after transformation\\n\", data_train['SqrSlope'].skew(), \n",
    "      \"\\nmin\\n\", data_train['SqrSlope'].min(),\n",
    "      \"\\nmax\\n\", data_train['SqrSlope'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['SqrSlope'], hist = True, fit = norm, kde = True,color= 'darkgreen', kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the skweness for the slope shows better performance when using the sqaure root, we will transform the variable into square root as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Horizontal_Distance_To_Fire_Points'<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['Horizontal_Distance_To_Fire_Points'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Horizontal_Distance_To_Fire_Points'].min(),\n",
    "      \"\\nmax\\n\", data_train['Horizontal_Distance_To_Fire_Points'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Horizontal_Distance_To_Fire_Points'], hist = True,  color='green',fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log_Horizontal_Distance_To_firepoints'] = np.log(data_train['Horizontal_Distance_To_Fire_Points']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew after log transformation\\n\", data_train['log_Horizontal_Distance_To_firepoints'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log_Horizontal_Distance_To_firepoints'].min(),\n",
    "      \"\\nmax\\n\", data_train['log_Horizontal_Distance_To_firepoints'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['sqr_Horizontal_Distance_To_firepoints'] = data_train['Horizontal_Distance_To_Fire_Points']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew after sqr transformation\\n\", data_train['sqr_Horizontal_Distance_To_firepoints'].skew(), \n",
    "      \"\\nmin\\n\", data_train['sqr_Horizontal_Distance_To_firepoints'].min(),\n",
    "      \"\\nmax\\n\", data_train['sqr_Horizontal_Distance_To_firepoints'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['sqr_Horizontal_Distance_To_firepoints'], hist = True, color= 'darkgreen',fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is less skewed after sqr transformation, we will also use sqr for the feature variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Hillshades<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Mean_Hillshade'] = (data_train['Hillshade_9am']+data_train['Hillshade_Noon']+data_train['Hillshade_3pm'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Mean_Hillshade'], hist = True, fit = norm,  color='green',kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['Mean_Hillshade'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Mean_Hillshade'].min(),\n",
    "      \"\\nmax\\n\", data_train['Mean_Hillshade'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log_Mean_Hillshade'] = np.log(data_train['Mean_Hillshade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['log_Mean_Hillshade'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log_Mean_Hillshade'].min(),\n",
    "      \"\\nmax\\n\", data_train['log_Mean_Hillshade'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['log_Mean_Hillshade'], hist = True, fit = norm, kde = True,color = 'orange', kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log10Mean_Hillshade'] = np.log10(data_train['Mean_Hillshade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['log10Mean_Hillshade'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log10Mean_Hillshade'].min(),\n",
    "      \"\\nmax\\n\", data_train['log10Mean_Hillshade'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['sqr_Mean_Hillshade'] = data_train['Mean_Hillshade']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['sqr_Mean_Hillshade'].skew(), \n",
    "      \"\\nmin\\n\", data_train['sqr_Mean_Hillshade'].min(),\n",
    "      \"\\nmax\\n\", data_train['sqr_Mean_Hillshade'].max(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use any transformation as the data does not improve. In the next step we will normalize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green> Aspect <font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['Aspect'].skew(), \n",
    "      \"\\nmin\\n\", data_train['Aspect'].min(),\n",
    "      \"\\nmax\\n\", data_train['Aspect'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['Aspect'], hist = True, color= 'darkgreen',fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['sqr_Aspect'] = data_train['Aspect']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['sqr_Aspect'].skew(), \n",
    "      \"\\nmin\\n\", data_train['sqr_Aspect'].min(),\n",
    "      \"\\nmax\\n\", data_train['sqr_Aspect'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.distplot(data_train['sqr_Aspect'], hist = True, color= 'darkgreen',fit = norm, kde = True, kde_kws = {'shade': True, 'linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log_Aspect'] = data_train['Aspect']**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['log_Aspect'] = np.log(data_train['Aspect']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skew before transformation\\n\", data_train['log_Aspect'].skew(), \n",
    "      \"\\nmin\\n\", data_train['log_Aspect'].min(),\n",
    "      \"\\nmax\\n\", data_train['log_Aspect'].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install htmltabletomd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import htmltabletomd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green> Summary<font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th><b>Features</b></th>\n",
    "    <th><b>Transformation</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "<td>ID  </td>\n",
    "    <td> Drop</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Distance To Hydrology  </td>\n",
    "    <td><b><i>Square Root</i></b> of the length of the side of horizontal and vertical </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sqr_Horizontal_Distance_To_Roadways</td>\n",
    "    <td><b>Square Root</b> of horizontal Distance to Roadways</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SqrSlope</td>\n",
    "    <td><b><i>Square Root</i></b> Slope</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sqr_Horizontal_Distance_To_firepoints</td>\n",
    "    <td><b><i>Square Root</i></b> Horizontal Distance to firepoints</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mean Hillshade</td>\n",
    "    <td><b><i>Average</i></b> of all Hillshades features</td>\n",
    "  <tr>      \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on which methodology we use to classify soil types!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Factorization\n",
    "\n",
    "The numerical values present a level of detail that may be much more fine-grained than we need. For instance, the soil level can be represented by different categories (soil family, complex or stony/rubberly). We aggregate the data up which can help to avoid overfitting when the data is more aggregate: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Discretization to bin the soil variable to the family type.<br>\n",
    "\n",
    "__Cathedral__ <br>\n",
    "1 Cathedral family - Rock outcrop complex, extremely stony.<br>\n",
    "\n",
    "__Ratake__ <br>\n",
    "2 Vanet - Ratake families complex, very stony.<br>\n",
    "4 Ratake family - Rock outcrop complex, rubbly.<br>\n",
    "\n",
    "__Vanet__<br>\n",
    "5 Vanet family - Rock outcrop complex complex, rubbly.<br>\n",
    "\n",
    "__Wetmore__<br>\n",
    "6 Vanet - Wetmore families - Rock outcrop complex, stony.<br>\n",
    "\n",
    "__Gothic__<br>\n",
    "7 Gothic family.<br>\n",
    "                    \n",
    "__Limber__ <br>\n",
    "8 Supervisor - Limber families complex. <br>\n",
    "\n",
    "__Troutville__<br>\n",
    "9 Troutville family, very stony.<br>\n",
    "\n",
    "__Legault__<br>\n",
    "12 Legault family - Rock land complex, stony.<br>\n",
    "29 Como - Legault families complex, extremely stony.<br>\n",
    "\n",
    "__Gateview__ <br>\n",
    "17 Gateview family - Cryaquolis complex.<br>\n",
    "\n",
    "__Rogert__<br>\n",
    "18 Rogert family, very stony.<br>\n",
    "\n",
    "\n",
    "__Como__<br>\n",
    "30 Como family - Rock land - Legault family complex, extremely stony.<br>\n",
    "\n",
    "__Bross__<br>\n",
    "36 Bross family - Rock land - Cryumbrepts complex, extremely stony.<br>\n",
    "\n",
    "\n",
    "\n",
    "__Catamount__<br>\n",
    "10 Bullwark - Catamount families - Rock outcrop complex, rubbly.<br>\n",
    "11 Bullwark - Catamount families - Rock land complex, rubbly.<br>\n",
    "13 Catamount family - Rock land - Bullwark family complex, rubbly.<br>\n",
    "26 Granile - Catamount families complex, very stony.<br>\n",
    "32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.<br>\n",
    "31 Leighcan - Catamount families complex, extremely stony.<br>\n",
    "33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.<br>\n",
    "\n",
    "__Leighcan__<br>\n",
    "21 Typic Cryaquolls - Leighcan family, till substratum complex.<br>\n",
    "22 Leighcan family, till substratum, extremely bouldery.<br>\n",
    "23 Leighcan family, till substratum - Typic Cryaquolls complex.<br>\n",
    "24 Leighcan family, extremely stony.<br>\n",
    "25 Leighcan family, warm, extremely stony.<br>\n",
    "27 Leighcan family, warm - Rock outcrop complex, extremely stony.<br>\n",
    "28 Leighcan family - Rock outcrop complex, extremely stony.<br>\n",
    "\n",
    "__Moran__<br>\n",
    "38 Leighcan - Moran families - Cryaquolls complex, extremely stony.<br>\n",
    "39 Moran family - Cryorthents - Leighcan family complex, extremely stony.<br>\n",
    "40 Moran family - Cryorthents - Rock land complex, extremely stony.<br>\n",
    "\n",
    "__Others__<br> \n",
    "3 Haploborolis - Rock outcrop complex, rubbly.<br>\n",
    "15 unspecified in the USFS Soil and ELU Survey.<br>\n",
    "37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.<br>\n",
    "34 Cryorthents - Rock land complex, extremely stony.<br>\n",
    "35 Cryumbrepts - Rock outcrop - Cryaquepts complex.<br>\n",
    "20 Typic Cryaquepts - Typic Cryaquolls complex.<br>\n",
    "14 Pachic Argiborolis - Aquolis complex.<br>\n",
    "16 Cryaquolis - Cryoborolis complex.<br>\n",
    "19 Typic Cryaquolis - Borohemists complex.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soil Type\n",
    "family_soil_types = {\n",
    "    'Family_Cathedral': ['Soil_Type1'],\n",
    "    'Family_Retake': ['Soil_Type2', 'Soil_Type4'],\n",
    "    'Family_Vanet': ['Soil_Type5'],\n",
    "    'Family_Wetmore': ['Soil_Type6'],\n",
    "    'Family_Gothic': ['Soil_Type7'],\n",
    "    'Family_Limber': ['Soil_Type8'],\n",
    "    'Family_Troutville_': ['Soil_Type9'],\n",
    "    'Family_Legault': ['Soil_Type12', 'Soil_Type29'],\n",
    "    'Family_Gateview': ['Soil_Type17'],\n",
    "    'Family_Rogert': ['Soil_Type18'],\n",
    "    'Family_Como': ['Soil_Type30'],\n",
    "    'Family_Bross': ['Soil_Type36'],\n",
    "    'Family_Catamount': ['Soil_Type10','Soil_Type11','Soil_Type13','Soil_Type26','Soil_Type32','Soil_Type31','Soil_Type33'],\n",
    "    'Family_Leighcan': ['Soil_Type21','Soil_Type22','Soil_Type23','Soil_Type24','Soil_Type25','Soil_Type27','Soil_Type28'],\n",
    "    'Family_Moran': ['Soil_Type38','Soil_Type39','Soil_Type40'],\n",
    "    'Family_Others': ['Soil_Type3','Soil_Type15','Soil_Type37','Soil_Type34','Soil_Type35','Soil_Type20','Soil_Type14','Soil_Type16','Soil_Type19'],\n",
    "} \n",
    "\n",
    "for family in family_soil_types:\n",
    "    data_train[family] = 0\n",
    "    soil_types = family_soil_types[family]\n",
    "    for soil_type in soil_types:\n",
    "        data_train[family] += data_train[soil_type]\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group the soil types according to their family and according to the complex and stonyness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Group <br>\n",
    "__Rock_outcrop_complex__ <br>\n",
    "1 Cathedral family - Rock outcrop complex, extremely stony.<br>\n",
    "2 Vanet - Ratake families complex, very stony.<br>\n",
    "3 Haploborolis - Rock outcrop complex, rubbly.<br>\n",
    "4 Ratake family - Rock outcrop complex, rubbly.<br>\n",
    "5 Vanet family - Rock outcrop complex complex, rubbly.<br>\n",
    "6 Vanet - Wetmore families - Rock outcrop complex, stony.<br>\n",
    "10 Bullwark - Catamount families - Rock outcrop complex, rubbly.<br>\n",
    "27 Leighcan family, warm - Rock outcrop complex, extremely stony.<br>\n",
    "28 Leighcan family - Rock outcrop complex, extremely stony.<br>\n",
    "33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.<br>\n",
    "\n",
    "__Ratake_families_complex__<br>\n",
    "2 Vanet - Ratake families complex, very stony.<br>\n",
    "\n",
    "\n",
    "__Limber families complex__<br>\n",
    "8 Supervisor - Limber families complex.<br>\n",
    "\n",
    "__rock land complex__<br>\n",
    "11 Bullwark - Catamount families - Rock land complex, rubbly.<br>\n",
    "12 Legault family - Rock land complex, stony.<br>\n",
    "34 Cryorthents - Rock land complex, extremely stony.<br>\n",
    "40 Moran family - Cryorthents - Rock land complex, extremely stony.<br>\n",
    "\n",
    "__Cryoborolis complex__<br>\n",
    "16 Cryaquolis - Cryoborolis complex.<br>\n",
    "17 Gateview family - Cryaquolis complex.<br>\n",
    "\n",
    "__Bullwark family complex__<br>\n",
    "13 Catamount family - Rock land - Bullwark family complex, rubbly.<br>\n",
    "\n",
    "__Aquolis complex__<br>\n",
    "14 Pachic Argiborolis - Aquolis complex.<br>\n",
    "\n",
    "__Borohemists complex__<br>\n",
    "19 Typic Cryaquolis - Borohemists complex.<br>\n",
    "\n",
    "__Cryaquolls complex__<br>\n",
    "20 Typic Cryaquepts - Typic Cryaquolls complex.<br>\n",
    "23 Leighcan family, till substratum - Typic Cryaquolls complex.<br>\n",
    "38 Leighcan - Moran families - Cryaquolls complex, extremely stony.<br>\n",
    "\n",
    "__till substratum complex__<br>\n",
    "21 Typic Cryaquolls - Leighcan family, till substratum complex.<br>\n",
    "\n",
    "__Catamount families complex__<br>\n",
    "26 Granile - Catamount families complex, very stony.<br>\n",
    "1 Leighcan - Catamount families complex, extremely stony.<br>\n",
    "31 Leighcan - Catamount families complex, extremely stony.<br>\n",
    "\n",
    "__Legault families complex__<br>\n",
    "29 Como - Legault families complex, extremely stony.<br>\n",
    "30 Como family - Rock land - Legault family complex, extremely stony.<br>\n",
    "\n",
    "__Leighcan family complex__<br>\n",
    "32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.<br>\n",
    "39 Moran family - Cryorthents - Leighcan family complex, extremely stony.<br>\n",
    "\n",
    "__Cryaquepts complex__<br>\n",
    "35 Cryumbrepts - Rock outcrop - Cryaquepts complex.<br>\n",
    "\n",
    "__Cryumbrepts complex__<br>\n",
    "36 Bross family - Rock land - Cryumbrepts complex, extremely stony.<br>\n",
    "\n",
    "__Cryorthents complex__<br>\n",
    "37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.<br>\n",
    "\n",
    "__others__ <br>\n",
    "7 Gothic family.<br>\n",
    "9 Troutville family, very stony.<br>\n",
    "22 Leighcan family, till substratum, extremely bouldery.<br>\n",
    "24 Leighcan family, extremely stony.<br>\n",
    "25 Leighcan family, warm, extremely stony.<br>\n",
    "18 Rogert family, very stony.<br>\n",
    "15 unspecified in the USFS Soil and ELU Survey.<br>\n",
    "\n",
    "\n",
    "Source: https://www.kaggle.com/competitions/forest-cover-type-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Type\n",
    "family_complex_types = {\n",
    "    'Rock_outcrop_complex': ['Soil_Type1','Soil_Type2','Soil_Type3','Soil_Type4','Soil_Type5','Soil_Type6','Soil_Type10','Soil_Type27','Soil_Type28','Soil_Type33'],\n",
    "    'Ratake_families_complex': ['Soil_Type2'],\n",
    "    'Limber_families_complex': ['Soil_Type8'],\n",
    "    'Rock_land_complex': ['Soil_Type11','Soil_Type12','Soil_Type34','Soil_Type40'],\n",
    "    'Cryoborolis_complex': ['Soil_Type16','Soil_Type17'],\n",
    "    'Bullwark_family_complex': ['Soil_Type13'],\n",
    "    'Aquolis_complex_': ['Soil_Type14'],\n",
    "    'Borohemists_complex': ['Soil_Type19'],\n",
    "    'Cryaquolls_complex': ['Soil_Type20','Soil_Type23','Soil_Type38'],\n",
    "    'Till_substratum_complex': ['Soil_Type21'],\n",
    "    'Catamount_families_complex': ['Soil_Type26','Soil_Type1','Soil_Type31'],\n",
    "    'Legault_families_complex': ['Soil_Type39','Soil_Type30'],\n",
    "    'Leighcan_family_complex': ['Soil_Type32','Soil_Type39'],\n",
    "    'Cryaquepts_complex': ['Soil_Type35'],\n",
    "    'Cryumbrepts_complex': ['Soil_Type36'],\n",
    "    'Cryorthents_complex': ['Soil_Type37'],\n",
    "    'others_complex': ['Soil_Type7','Soil_Type9','Soil_Type22','Soil_Type24','Soil_Type25','Soil_Type18','Soil_Type15'],\n",
    "} \n",
    "\n",
    "for family in family_complex_types:\n",
    "    data_train[family] = 0\n",
    "    complex_types = family_complex_types[family]\n",
    "    for complex_type in complex_types:\n",
    "        data_train[family] += data_train[complex_type]\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stony__ <br>\n",
    "1 Cathedral family - Rock outcrop complex, extremely stony.<br>\n",
    "2 Vanet - Ratake families complex, very stony.<br>\n",
    "6 Vanet - Wetmore families - Rock outcrop complex, stony.<br>\n",
    "9 Troutville family, very stony.<br>\n",
    "12 Legault family - Rock land complex, stony.<br>\n",
    "18 Rogert family, very stony.<br>\n",
    "24 Leighcan family, extremely stony.<br>\n",
    "25 Leighcan family, warm, extremely stony.<br>\n",
    "26 Granile - Catamount families complex, very stony.<br>\n",
    "27 Leighcan family, warm - Rock outcrop complex, extremely stony.<br>\n",
    "28 Leighcan family - Rock outcrop complex, extremely stony.<br>\n",
    "29 Como - Legault families complex, extremely stony.<br>\n",
    "30 Como family - Rock land - Legault family complex, extremely stony.<br>\n",
    "31 Leighcan - Catamount families complex, extremely stony.<br>\n",
    "32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.<br>\n",
    "33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.<br>\n",
    "34 Cryorthents - Rock land complex, extremely stony.<br>\n",
    "36 Bross family - Rock land - Cryumbrepts complex, extremely stony.<br>\n",
    "37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.<br>\n",
    "38 Leighcan - Moran families - Cryaquolls complex, extremely stony.<br>\n",
    "39 Moran family - Cryorthents - Leighcan family complex, extremely stony.<br>\n",
    "40 Moran family - Cryorthents - Rock land complex, extremely stony.<br>\n",
    "\n",
    "__Rubbly__<br>\n",
    "3 Haploborolis - Rock outcrop complex, rubbly.<br>\n",
    "4 Ratake family - Rock outcrop complex, rubbly.<br>\n",
    "5 Vanet family - Rock outcrop complex complex, rubbly.<br>\n",
    "10 Bullwark - Catamount families - Rock outcrop complex, rubbly.<br>\n",
    "11 Bullwark - Catamount families - Rock land complex, rubbly.<br>\n",
    "13 Catamount family - Rock land - Bullwark family complex, rubbly.<br>\n",
    "\n",
    "__others__<br>\n",
    "7 Gothic family.<br>\n",
    "8 Supervisor - Limber families complex.<br>\n",
    "14 Pachic Argiborolis - Aquolis complex.<br>\n",
    "15 unspecified in the USFS Soil and ELU Survey.<br>\n",
    "16 Cryaquolis - Cryoborolis complex.<br>\n",
    "17 Gateview family - Cryaquolis complex.<br>\n",
    "19 Typic Cryaquolis - Borohemists complex.<br>\n",
    "20 Typic Cryaquepts - Typic Cryaquolls complex.<br>\n",
    "21 Typic Cryaquolls - Leighcan family, till substratum complex.<br>\n",
    "22 Leighcan family, till substratum, extremely bouldery.<br>\n",
    "23 Leighcan family, till substratum - Typic Cryaquolls complex.<br>\n",
    "35 Cryumbrepts - Rock outcrop - Cryaquepts complex.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soil Type\n",
    "family_types = {\n",
    "    'Type_Stony': ['Soil_Type1','Soil_Type2', 'Soil_Type6', 'Soil_Type9', 'Soil_Type12', 'Soil_Type18', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40'],\n",
    "    'Type_Rubbly': ['Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type10', 'Soil_Type11', 'Soil_Type13'],\n",
    "    'Type_Other': ['Soil_Type7','Soil_Type8', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type35']\n",
    "} \n",
    "\n",
    "for family in family_types:\n",
    "    data_train[family] = 0\n",
    "    soil_types = family_types[family]\n",
    "    for soil_type in soil_types:\n",
    "        data_train[family] += data_train[soil_type]\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select zero values of Hillshade 3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_train[data_train['Hillshade_3pm']==0]\n",
    "print(df_original.shape)\n",
    "df_original.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data_train.loc[data_train['Hillshade_3pm'] != 0]\n",
    "print(data1.shape)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data_train.drop(columns =['Wilderness','Soil','Cover_Type1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data1['Hillshade_3pm']\n",
    "X_train = data1.drop('Hillshade_3pm', axis=1)\n",
    "X_test = data1. drop('Hillshade_3pm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "data_train.loc[data_train['Hillshade_3pm']==0, 'Hillshade_3pm' ] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hillshade, create mean of all Hillshade variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Mean_Hilshade'] = (data_train['Hillshade_9am']+data_train['Hillshade_Noon']+data_train['Hillshade_3pm'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Mean_Hilshade'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#creating distance to hydrology as a function of horizontal and vertical \n",
    "forestdata$Euclidean_Distance_To_Hydrology = (forestdata$Horizontal_Distance_To_Hydrology^2 + forestdata$Vertical_Distance_To_Hydrology^2)^.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "  \n",
    "  \n",
    "fig = go.Figure()\n",
    "  \n",
    "\n",
    "  \n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    y=data_train.Horizontal_Distance_To_Hydrology,\n",
    "    name='Horizontal_Distance_To_Hydrology',\n",
    "    boxpoints=\"outliers\",\n",
    "    marker_color='lightcyan'\n",
    "))\n",
    "  \n",
    "fig.add_trace(go.Box(\n",
    "    y=data_train.Vertical_Distance_To_Hydrology,\n",
    "    name='Vertical_Distance_To_Hydrology',\n",
    "    marker_color='magenta'\n",
    "))\n",
    "   \n",
    "fig.update_layout(\n",
    "  \n",
    "    # group together boxes of the different\n",
    "    # traces for each value of x\n",
    "    boxmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
