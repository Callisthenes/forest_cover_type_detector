{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml2_group_assignment.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green> Introduction </font>\n",
    "\n",
    "This is a continuation of forest_cover_type_detector_gr_a_Part2.\n",
    "\n",
    "Above we import the files created in the previous notebook so that this notebook can run independently\n",
    "\n",
    "Table of contents is an extension of the previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tree_types.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green> Table of contents </font>\n",
    "\n",
    "* [Libaries used](#0)\n",
    "* [1. Import Data](#1)\n",
    "  * [1.1.Original Data & Standardization](#1.1)\n",
    "  * [1.2.All features & Standardization](#1.2)  \n",
    "  * [1.3.Features selected & Standardization](#1.3)   \n",
    "  \n",
    "* [__2.Rerun the model on selected Features__](#2)  \n",
    "  * [2.1.Correlation Heatmap](#2.1)\n",
    "      * [2.1.1 Removing correlated features](#2.1.1)\n",
    "      \n",
    "* [__7. ML Algorithms after feature selection__](#7)\n",
    "  * [7.1 Decision Trees](#7.1)\n",
    "      * [7.1.1 Single Tree](#7.1.1)\n",
    "  * [7.2 XGBoost](#7.2)  \n",
    "  * [7.3 Extra Tree Classifier](#7.3)\n",
    "  * [7.4 Random Forest](#7.4)    \n",
    "      * [7.4.1 Bagging](#7.1.1)  \n",
    "  * [7.5 KNN](#7.5)\n",
    "  * [7.6 SVM](#7.6)\n",
    "  * [7.7 Naive Bayes](#7.7)\n",
    "  * [7.8 Logistic Regression](#7.8)\n",
    "  * [7.9 Ensemble Methods](#7.4)\n",
    "  \n",
    "  \n",
    "* [__8. ML Algorithms after Dimensionality Reduction__](#8)\n",
    "  * [8.1 PCA Dimensionality reduction ](#8.1)\n",
    "      * [8.1.1 Random Forest](#8.1.1)\n",
    "      * [8.1.2 XGBoost](#8.1.2)      \n",
    "      * [8.1.3 Logistic Regression](#8.1.3)     \n",
    "      * [8.1.4 Extra Tree Classifier](#8.1.4)\n",
    "      * [8.1.5 Ensemble Methods](#8.1.5)      \n",
    "  * [8.2 LDA Dimensionality reduction ](#8.2)      \n",
    "  \n",
    "* [9. Final Submission](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# <font color=green> Libraries used </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install squarify\n",
    "#!pip install GraphViz\n",
    "#pip install pygraphviz\n",
    "#!pip install pydotplus\n",
    "#!pip install xgboost\n",
    "#!pip install dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import pydotplus\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import squarify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/5bc1x9p158vgc4774v7r2tq40000gn/T/ipykernel_2554/627927963.py:66: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 16px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, learning_curve, ShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB #BernoulliNB is designed for binary/boolean features\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from dtreeviz.trees import *\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from IPython.display import Image  \n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Image  \n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
    "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "#  <font color=darkgreen>1.Import the Data </font>\n",
    "<a id='1.1'></a>\n",
    "###  <font color=green>1.1. Original Data </font>\n",
    "Letâ€™s load the previous data and results from previous notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565892, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = data_train.columns\n",
    "num  = [column for column in column_list if 'Soil' not in column and 'Wilderness_Area' not in  column and 'Aspect_North' not in  column and 'Climate' not in  column and 'Family' not in  column and 'Type' not in  column and 'complex' not in  column and 'Aspect_East' not in  column and 'Aspect_South' not in  column and 'Aspect_West' not in  column ]\n",
    "cat= [column for column in column_list if column not in num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "##  <font color=green>1.3. Selected Model after Feature Selection & Standardization </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected features from the feature selection are transferred to cvs and used for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected1 = pd.read_csv(\"X_selected.csv\")\n",
    "y_selected1 = pd.read_csv(\"y_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected1 = X_selected1[X_selected1.columns.drop(list(X_selected1.filter(regex='Unnamed:')))]\n",
    "y_selected1 = y_selected1[y_selected1.columns.drop(list(y_selected1.filter(regex='Unnamed:')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 22)\n",
      "(15120, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_selected1.shape)\n",
    "print(y_selected1.shape)\n",
    "\n",
    "if X_selected1.shape[0] != y_selected1.shape[0]:\n",
    "  print(\"X and y rows are mismatched, check dataset again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to filter out the dummy variables for the normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = X_selected1.columns\n",
    "scale_numerical  = [column for column in column_list if 'Soil' not in column and 'Wilderness_Area' not in  column and 'Aspect_North' not in  column and 'Climate' not in  column and 'Family' not in  column and 'Type' not in  column and 'complex' not in  column and 'Aspect_East' not in  column and 'Aspect_South' not in  column and 'Aspect_West' not in  column ]\n",
    "scale_categorial= [column for column in column_list if column not in scale_numerical ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and validation test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of validation data:(3024, 22) and (3024, 1) \n",
      "The shape of training data:(12096, 22) and (12096, 1) \n"
     ]
    }
   ],
   "source": [
    "column_list = X_selected1.columns\n",
    "\n",
    "X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(X_selected1, y_selected1, test_size=0.20, random_state=37,stratify=y_selected1)\n",
    "print(\"The shape of validation data:{} and {} \".format(X_val_new.shape,y_val_new.shape))\n",
    "print(\"The shape of training data:{} and {} \".format(X_train_new.shape,y_train_new.shape))\n",
    "y_val_new = y_val_new.values.ravel()\n",
    "y_train_new = y_train_new.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# <font color=darkgreen> 2.Re-run models with the new selected features  <font>\n",
    "Some classes such as SDG classifier , Random Forest classifier and naive Bayes classifier can handle mutliple classes naively. \n",
    "    \n",
    "Others like logistic regression or Support Vector Machine classifier are stricly binary classifier. However there are various strategies to perform multiclass classification with multiple binary classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataFrame to compare performance of Classifier Models in the End\n",
    "classifiers_compare = pd.DataFrame(columns =['Algorithm','Mean CV Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## <font color=green> 2.1 Correlation Heatmap  <font>\n",
    "Checking Correlation among features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Heatmap - Checking for autocorrelation among variables \n",
    "matrix = X_selected1.corr()\n",
    "mask = np.zeros_like(matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(50,20))\n",
    "heatmap = sns.heatmap(matrix, center=0, fmt=\".3f\", square=True, annot=True, linewidth=1.3, mask = mask,vmax=0.9);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.1'></a>\n",
    "## <font color=green> 2.1.1 Removing autocorrelation <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these features are heavily correlated one another, before running the models like Logistic Regression, where mutlicorrelaty is an issue, we should ensure, only relevant features are considered, taking a threshold of 0.7 these are:\n",
    "\n",
    "- Wilderness Area 1 \n",
    "- Subalpine Climate (synthetic)\n",
    "- Wilderness Area 3\n",
    "- Elevation\n",
    "- Family Moran (synthetic)\n",
    "- Soil Type 3\n",
    "- Soil Type 12\n",
    "- Rock outcrop complex (synthetic)\n",
    "- Lower Montane Climate (synthetic)\n",
    "- Family Catamount (synthetic)\n",
    "\n",
    "TOTAL: 11 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for logistic regression, Stephanie will decide if we keep it or not eventually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "    print('Removed Columns {}'.format(drops))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Collinearity features for logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logist = remove_collinear_features(X_selected1, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log, X_val_log, y_train_log, y_val_log = train_test_split(df_logist, y_selected1, test_size=0.20, random_state=37,stratify=y_selected1)\n",
    "print(\"The shape of validation data:{} and {} \".format(X_val_new.shape,y_val_new.shape))\n",
    "print(\"The shape of training data:{} and {} \".format(X_train_new.shape,y_train_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to plot the ROC curve later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_curve(model, X_train,y_train, X_val, y_val):\n",
    "\n",
    "    # Creating visualization with the readable labels\n",
    "    visualizer = ROCAUC(model, encoder={1: 'Spruce/Fir', \n",
    "                                        2: 'Lodgepole Pine', \n",
    "                                        3: 'Ponderosa Pine',\n",
    "                                       4: 'Cottonwood/Willow',\n",
    "                                       5: 'Aspen',\n",
    "                                       6: 'Douglas-fir',\n",
    "                                       7: 'Krummholz'})\n",
    "\n",
    "                                        \n",
    "    # Fitting to the training data first then scoring with the test data                                    \n",
    "    visualizer.fit(X_train,y_train)\n",
    "    visualizer.score(X_val, y_val)\n",
    "    visualizer.show()\n",
    "    \n",
    "    return visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "# <font color=darkgreen> 7.ML Algorithms before Dimensionality Reduction  <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green> 7.1. Decision Trees  <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to plot the trees is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(tree, feature_names):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data, feature_names=feature_names, filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.1.1'></a>\n",
    "### <font color=green> 7.1.1. Single Tree <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt is with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree = DecisionTreeClassifier(random_state=18)\n",
    "model_tree = single_tree.fit(X_train_new, y_train_new)\n",
    "print(\"Accuracy = {0:.4f}\".format(-np.mean(cross_val_score(single_tree, X_train_new, y_train_new, scoring='accuracy'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model_tree, X_train_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two aspects can be highlighted after taking a look at the tree:\n",
    " - The tree is huge! As we have not set any complexity pruning or max_depth we have allow the tree to grow without any limit\n",
    " - Alpine Climate and Binned elevantion seem to be the most important features in order to predict the value of cover type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAPT THIS SO IT CAN BE A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prune the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': range(1,30)}\n",
    "\n",
    "single_tree_a = GridSearchCV(single_tree,\n",
    "                            param_grid,\n",
    "                            scoring='accuracy',\n",
    "                            cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "single_tree_a.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(single_tree_a.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = single_tree_a.cv_results_['mean_test_score']\n",
    "stds = single_tree_a.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, single_tree_a.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/-%0.03f) for %r\" % (-mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I stop here, to be continued later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.errorbar(range(1,30,1), [-m for m in means], yerr=stds, fmt='-o')\n",
    "plt.title('MSE for different Depths', fontsize=20)\n",
    "plt.xlabel(\"Depth\", fontsize=16)\n",
    "plt.ylabel(\"MSE\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_pruned = DecisionTreeClassifier(random_state=18, max_depth=15)\n",
    "\n",
    "print(\"MSE = {0:.4f}\".format(-np.mean(cross_val_score(single_tree_pruned, X_train_new, y_train_new, scoring='neg_mean_squared_error'))))\n",
    "print(\"Accuracy Train= {0:.4f}\".format(np.mean(cross_val_score(single_tree_pruned, X_train_new, y_train_new))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the plot, the optimal value for the depth of the decision tree is 15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(single_tree_pruned.fit(X_train_new,y_train_new), X_train_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtreeviz(single_tree_pruned, X_train_new,y_train_new, target_name='Cover_Type', feature_names=X_train_new.columns, \n",
    "        fontname='DejaVu Sans', scale=1.5,label_fontsize=10, fancy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the same decision tree with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(random_state=37)\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(tree_classifier, X_train_new, y_train_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": randint(12,25), # default 100\n",
    "    \"max_leaf_nodes\":[5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "forest_hyper = RandomizedSearchCV(tree_classifier, param_distributions=params, random_state=37, n_iter=150, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "forest_hyper.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(forest_hyper.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = forest_hyper.cv_results_['mean_test_score']\n",
    "stds = forest_hyper.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, forest_hyper.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best= forest_hyper.best_estimator_\n",
    "dt_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(criterion = forest_hyper.best_params_['criterion'], max_depth=forest_hyper.best_params_['max_depth'], max_leaf_nodes= forest_hyper.best_params_['max_leaf_nodes'], random_state=37)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_treeclassifer = tree_classifier.fit(X_train_new,y_train_new)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_tree = model_treeclassifer.predict(X_train_new)\n",
    "print('\\nTarget on train data',predict_tree)\n",
    "\n",
    "# Accuracy Score on train dataset\n",
    "accuracy_tree_train = accuracy_score(y_train_new, predict_tree)\n",
    "print('\\nAccuracy_score on train dataset : ', accuracy_tree_train)\n",
    "\n",
    "# Predict the target on the test dataset\n",
    "predict_tree_test = model_treeclassifer.predict(X_val_new)\n",
    "print('\\nTarget on test data',predict_tree_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_tree_test = accuracy_score(y_val_new,predict_tree_test)\n",
    "print('\\nAccuracy on test dataset : ', accuracy_tree_test)\n",
    "\n",
    "#Best Paramater \n",
    "dt_best = forest_hyper.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(forest_hyper.cv_results_)\n",
    "score_df.nlargest(3,\"mean_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val_new, predict_tree_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val_new, predict_tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(tree_classifier, X_train_new,y_train_new, X_val_new, y_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ClassPredictionError(\n",
    "    tree_classifier)\n",
    "visualizer.fit(X_train_new, y_train_new)\n",
    "visualizer.score(X_val_new, y_val_new)\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2'></a>\n",
    "## <font color=green> 7.2. XGB Boost  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train1 = le.fit_transform(y_train_new)\n",
    "y_val1 = le.fit_transform(y_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First run, hyperparameters NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8437\n"
     ]
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(xgboost, X_train_new, y_train1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedro to test the best model and beat the best model do"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\n",
    "    \"max_depth\": randint(10,20,2), # default 100\n",
    "    \n",
    "    \"colsample_bytree\": uniform(0.7, 0.85),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"n_estimators\": randint(200, 400,50), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.95),\n",
    "    \"nthread\": [4] # parallel processing and number of cores in the system should be entered.\n",
    "}\n",
    "\n",
    "\n",
    "xgb_hyper = RandomizedSearchCV(xgboost, param_distributions=params, random_state=37, n_iter=150, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "xgb_hyper.fit(X_train_new, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(forest_hyper.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = forest_hyper.cv_results_['mean_test_score']\n",
    "stds = forest_hyper.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, forest_hyper.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping is an approach to training complex machine learning models to avoid overfitting.\n",
    "\n",
    "It works by monitoring the performance of the model that is being trained on a separate test dataset and stopping the training procedure once the performance on the test dataset has not improved after a fixed number of training iterations.\n",
    "\n",
    "It avoids overfitting by attempting to automatically select the inflection point where performance on the test dataset starts to decrease while performance on the training dataset continues to improve as the model starts to overfit.\n",
    "\n",
    "Source: https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(criterion = \"gini\", max_depth = 20, random_state=37, n_jobs=-1)\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(xgboost, X_train_new, y_train1))))\n",
    "xgboost.fit(X_train_new, y_train1, early_stopping_rounds=40, eval_metric=\"merror\", eval_set=[(X_val_new, y_val1)])\n",
    "pred = xgboost2.predict(X_val_new)\n",
    "\n",
    "accuracy = accuracy_score(y_val1, pred);\n",
    "print ('accuracy:%0.2f%%'%(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(xgboost, X_val_new, y_val1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8006\n"
     ]
    }
   ],
   "source": [
    "xgboost2 = xgb.XGBClassifier (missing=np.nan, max_depth=10, n_estimators=350, random_state=37, learning_rate=0.03, nthread=4, subsample=0.95, colsample_bytree=0.85, seed=42)\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(xgboost2, X_val_new, y_val1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.3'></a>\n",
    "## <font color=green> 7.3. Extra Tree Classifier  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "n_estimators = list(range(50, 250,5))\n",
    "n_estimators = [113]\n",
    "criterion=['gini','entropy']\n",
    "#min_samples_leaf = list(range(5, 25))\n",
    "#min_samples_split = list(range(5, 25))\n",
    "#max_depth = list(range(8, 50))\n",
    "max_depth = [22]\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_estimators=n_estimators, criterion=criterion)\n",
    "\n",
    "forest = ExtraTreesClassifier(random_state=0)\n",
    "grid_etc = RandomizedSearchCV(forest, param_grid, cv=5, scoring=\"accuracy\" ,return_train_score=False)\n",
    "grid_etc.fit(X_train_new, y_train_new)\n",
    "print(\"The best score: \",grid_etc.best_score_.round(4))\n",
    "#Parameter setting that gave the best results on the hold out data.\n",
    "print(\"The best parameter: \",grid_etc.best_params_)\n",
    "grid_etc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Feature importance\n",
    "etc_selected = ExtraTreesClassifier(n_estimators=grid_etc.best_params_['n_estimators'],\n",
    "                            criterion=grid_etc.best_params_['criterion'],random_state=0)\n",
    "etc_selected.fit(X_train_new, y_train_new)\n",
    "etc_sel_acc = etc_selected.score(X_val_new,y_val_new)\n",
    "print(\"The accuracy score of the ExtraTreesClassifier with the selected features: \",round(etc_sel_acc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(etc_selected, X_val_new, y_val_new))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.4'></a>\n",
    "## <font color=green> 7.4. Random Forest  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20)\n",
    "model_forest = forest.fit(X_train_new,y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_val_new,y_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test set\n",
    "y_pred_test_forest = forest.predict(X_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_val_new, y_pred_test_forest)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', \n",
    "               'Cottonwood/Willow', 'Aspen', 'Douglas-fir',    \n",
    "               'Krummholz']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val_new, y_pred_test_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20, random_state=37)\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(forest, X_train_new, y_train_new))))\n",
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(forest, X_val_new, y_val_new))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.5'></a>\n",
    "  ## <font color=green> 7.5. KNN  <font>\n",
    "KNN is better on smaller dataset, however we will evaluate the performance of this model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out the best value for k we will use a for loop, and with the range from 1 to 200 range (1,200,10). I reduced the range to 10 but will use iterations of 1. And it gives me the best K = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors_list = range (1,100,1)\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for k in k_neighbors_list:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, p=2) # using manhattan_distance \n",
    "    clf.fit(X_train_new, y_train_new)\n",
    "    y_pred_test = clf.predict(X_val_new)\n",
    "    acc_k = accuracy_score(y_val_new, y_pred_test)\n",
    "    \n",
    "    results_list.append({\n",
    "        \"k\": k,\n",
    "        \"acc\": acc_k\n",
    "    })\n",
    "    \n",
    "results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = 1 (Manhatten Distance), the best k = 8 with accuracy= 0.759259\n",
    "p = 2 (Euclidean Distance), the best k = 1 with accuracy = 0.761905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the best value for K and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = results.sort_values('acc', ascending = False) \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['k'],results['acc'])\n",
    "plt.xlabel('Valie for k for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors_list = range (1,40,1)\n",
    "\n",
    "K_scores = []\n",
    "\n",
    "for k in k_neighbors_list:\n",
    "    # Run KNeighborsClassifier with k neighbours \n",
    "    knn = KNeighborsClassifier(n_neighbors=k, p=1) # using manhattan_distance \n",
    "    # Obtain Cross_val_score for KneighborsClassifier with k neighbors \n",
    "    scores = cross_val_score(knn,X_train_new, y_train_new, cv= 5, scoring= \"accuracy\")\n",
    "    # Append mean of scores for K neighbors to k_scores list \n",
    "    K_scores.append({\n",
    "        \"k\": k,\n",
    "        \"acc\": scores.mean\n",
    "    })\n",
    "    \n",
    "results = pd.DataFrame(K_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = results.sort_values(K_scores, ascending = False) \n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Grridsearch and cross validation we will adapt the model. <br>\n",
    "We first create a KNN classifier instance and then prepare a range of values of hyperparameter K from 1 to 31 that will be used by GridSearchCV to find the best value of K.\n",
    "\n",
    "Furthermore, we set our cross-validation batch sizes cv = 5 and set scoring metrics as accuracy as our preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_valid_scores = {}\n",
    "parameters = {\n",
    "    \"n_neighbors\": list(range(1,20,1)),\n",
    "    \"leaf_size\":list(range(1,100,20)),\n",
    "    \"metric\":[\"euclidean\",\"manhattan\"]    \n",
    "}\n",
    "\n",
    "model_KNN = KNeighborsClassifier()\n",
    "\n",
    "model_KNN = GridSearchCV(\n",
    "    model_KNN,\n",
    "    parameters,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\"\n",
    "\n",
    ")\n",
    "KNN_results = model_KNN.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_results.best_score_\n",
    "KNN_results.best_estimator_\n",
    "KNN_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = KNN_results.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(model_KNN, X_train_new, y_train_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {0:.4f}\".format(np.mean(cross_val_score(model_KNN, X_val_new, y_val_new))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best model to calculate the mean cross validation score to compare the model later with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,leaf_size=1,metric='euclidean')\n",
    "\n",
    "scores = cross_val_score(knn, X_train_new, y_train_new, cv = 10, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {0:.4f}\\n\".format(accuracy_score(model_KNN.predict(X_val_new), y_val_new)))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(model_KNN.predict(X_val_new), y_val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_KNN,X_val_new, y_val_new,cmap=plt.cm.Blues,values_format='d' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_compare = classifiers_compare.append({'Algorithm': \"KNN\", 'Mean CV Score':(scores.mean())},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN is simple to use and can return very accurate and meaningful results. It also has a tendency to be computationally expensive, so it may not be your best choice for larger datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.6'></a>\n",
    "## <font color=green> 7.6. SVM  <font>\n",
    "The multiclass problem is broken down to multiple binary classification cases, which is also called one-vs-one. In scikit-learn one-vs-one is not default and needs to be selected explicitly (as can be seen further down in the code). One-vs-rest is set as default. It basically divides the data points in class x and rest. Consecutively a certain class is distinguished from all other classes.  The penalty term C is set to 1 for all classifiers. For the multiclass classification, the type one-versus-one is specified, as can be seen in decision_function_shape=â€™ovoâ€™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_clf = OneVsRestClassifier(svm.SVC(C=10,kernel='rbf'))\n",
    "ovr_clf.fit(X_train_new, y_train_new)\n",
    "print(\"SVM Accuracy = {:.4f}\".format(np.mean(cross_val_score(ovr_clf, X_train_new, y_train_new))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model output is not very good, lets fine tune the SVM parameters to further improve the model performance. \n",
    "_C_ is the balance between margin violations (low C) or better generalization of the models. _Gamma_ acts like a regularization hyperparamter. If the model is overfitting it is advisable to redeuce it.If it is underfitting you should increase it. The best Kernel to use if the dataset is large is _Gaussoan RBF kernel_. Since we already used Polynominal in our dataset we will disregard this option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_set = OneVsRestClassifier(SVC(kernel=\"rbf\"))\n",
    "\n",
    "parameters = {\n",
    "    \"estimator__C\": [1,10,100],\n",
    "    \"estimator__gamma\":[0.01,0.0001,0.00001],\n",
    "}\n",
    "\n",
    "estimator = GridSearchCV(model_to_set, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "estimator.fit(X_train_new, y_train_new)\n",
    "\n",
    "print(estimator.best_score_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (estimator.best_params_, estimator.best_score_))\n",
    "\n",
    "\n",
    "scores = estimator.cv_results_['mean_test_score'].reshape(len(parameters['estimator__C']), len(parameters['estimator__gamma']))\n",
    "\n",
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(parameters['estimator__gamma'])), parameters['estimator__gamma'], rotation=45)\n",
    "plt.yticks(np.arange(len(parameters['estimator__C'])), parameters['estimator__C'])\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = estimator.best_estimator_\n",
    "Y_pred = final_model.predict(X_val_new)\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(X_train_new , y_train_new))\n",
    "print(\"Testing  set score for SVM: %f\" % final_model.score(X_val_new  , y_val_new ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(final_model, X_train_new, y_train_new, cv = 10, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(final_model.predict(X_val_new), y_val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(final_model,X_val_new, y_val_new,cmap=plt.cm.Blues,values_format='d' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_compare = classifiers_compare.append({'Algorithm': \"SVM\", 'Mean CV Score':(scores.mean())},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2'></a>\n",
    "## <font color=green> 7.7. Naive Bayes  <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a classification problem with multiple discrete values we use the multinominal Naive Bayes method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "mnb = BernoulliNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "mnb.fit(X_train_new,y_train_new)\n",
    "\n",
    "#Predict Output\n",
    "y_pred= mnb.predict(X_val_new)\n",
    "scores = cross_val_score(mnb,X_train_new,y_train_new,cv = 5, scoring = \"accuracy\")\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Mean Accuracy:\",scores.mean())\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_val_new, y_pred))\n",
    "\n",
    "classifiers_compare = classifiers_compare.append({'Algorithm': \"Naive Bayes\", 'Mean CV Score':(scores.mean())},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.8'></a>\n",
    "## <font color=green> 7.8. Logistic Regression <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = y_train_log.values.ravel()\n",
    "y_val_log = y_val_log.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Logistic Regression with only the New PCA reduced dataset provided & L1 Regularization\n",
    "C_range=[0.001,0.01,0.02,0.04]\n",
    "scores_logreg=[]\n",
    "for c in C_range:\n",
    "    #Saga is good for larger Datasets \n",
    "    logreg = LogisticRegression(C=c, penalty ='l1', solver='saga', multi_class='multinomial',max_iter=5000)\n",
    "    logreg.fit(X_train_log, y_train_log)\n",
    "    y_pred = logreg.predict(X_val_log)\n",
    "    scores_logreg.append(metrics.accuracy_score(y_val_log,y_pred))\n",
    "\n",
    "    \n",
    "#Plot Logistic Regression with only the data provided\n",
    "plt.plot(C_range,scores_logreg)\n",
    "plt.xlabel(\"Values of Regularization Parameter\")\n",
    "plt.ylabel(\"Testing accuracy with Feature Engineering\")\n",
    "max(scores_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.9'></a>\n",
    "## <font color=green> 7.9. Ensemble methods<font>\n",
    "\n",
    "__Voting Classifier__   \n",
    "\n",
    "A very simple way to create an even better classifier is to aggregate the best predictions of each classifier and predict the class that gets the most votes. Normally this method is a better predictor than the single models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "    ('etc', etc_selected), ('knn',KNN_results),('xgboost',xgboost2)],voting='hard')\n",
    "eclf.fit(X_train_new, y_train1)\n",
    "y_val_pred = eclf.predict(X_val_new)\n",
    "print(\"Accuracy achieved by ensembling\",metrics.accuracy_score(y_val1,y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "#  <font color=darkgreen>9.Final Submission </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred=forest.predict(data_test.drop(labels=['Id','Wilderness','Soil'], axis=1))\n",
    " \n",
    " \n",
    " \n",
    "submission=pd.DataFrame(data=pred,columns=['Cover_Type'])\n",
    "submission\n",
    " \n",
    " \n",
    " \n",
    "submission['Id']=data_test['Id']\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
